{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path for storing the data-set on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 data-set is about 163 MB and will be downloaded automatically if it is not located in the given path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the class-names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training-set. This returns the images, the class-numbers as integers, and the class-numbers as One-Hot encoded arrays called labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 data-set has now been loaded and consists of 60,000 images and associated labels (i.e. classifications of the images). The data-set is split into 2 mutually exclusive sub-sets, the training-set and the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t50000\n",
      "- Test-set:\t\t10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(images_train)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(images_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dimensions are used in several places in the source-code below. They have already been defined in the cifar10 module, so we just need to import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cifar10 import img_size, num_channels, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are 32 x 32 pixels, but we will crop the images to 24 x 24 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size_cropped = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_image(image, training):\n",
    "    # This function takes a single image as input,\n",
    "    # and a boolean whether to build the training or testing graph.\n",
    "    \n",
    "    if training:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Randomly crop the input image.\n",
    "#        image = tf.random_crop(image, size=[img_size_cropped, img_size_cropped, num_channels])\n",
    "\n",
    "        # Randomly flip the image horizontally.\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        \n",
    "        # Randomly adjust hue, contrast and saturation.\n",
    "        image = tf.image.random_hue(image, max_delta=0.05)\n",
    "        image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.0, upper=2.0)\n",
    "\n",
    "        # Some of these functions may overflow and result in pixel\n",
    "        # values beyond the [0, 1] range. It is unclear from the\n",
    "        # documentation of TensorFlow whether this is\n",
    "        # intended. A simple solution is to limit the range.\n",
    "\n",
    "        # Limit the image pixels between [0, 1] in case of overflow.\n",
    "        image = tf.minimum(image, 1.0)\n",
    "        image = tf.maximum(image, 0.0)\n",
    "    else:\n",
    "        # For training, add the following to the TensorFlow graph.\n",
    "\n",
    "        # Crop the input image around the centre so it is the same\n",
    "        # size as images that are randomly cropped during training.\n",
    "        image = tf.image.resize_image_with_crop_or_pad(image,\n",
    "                                                       target_height=img_size_cropped,\n",
    "                                                       target_width=img_size_cropped)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(images, training):\n",
    "    # Use TensorFlow to loop over all the input images and call\n",
    "    # the function above which takes a single image as input.\n",
    "    images = tf.map_fn(lambda image: pre_process_image(image, training), images)\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name, exp=0):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial + exp, name=name, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_, out_channels, filter_height, filter_width, in_channels, strides):\n",
    "    W = weight_variable(shape=[filter_height, filter_width, in_channels, out_channels], name=\"weight\")\n",
    "    b = weight_variable(shape=[out_channels], name=\"bias\", exp=0.5)\n",
    "    res = tf.nn.conv2d(input_, W, strides, padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(res, b))\n",
    "    return relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(input_, size, strides, name=None):\n",
    "    return tf.nn.max_pool(input_, ksize=size,\n",
    "                          strides=strides,\n",
    "                          padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(input_, input_size, output_size, keep_prob, name=None):\n",
    "    fc_drop = tf.nn.dropout(input_, keep_prob, name=\"h_fc1_drop\")\n",
    "\n",
    "    W = weight_variable([input_size, output_size], \"weight\")\n",
    "    b = weight_variable([output_size], \"bias\", exp=0.5)\n",
    "\n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.matmul(fc_drop, W), b, name='y_conv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(input_):\n",
    "    flatten = tf.reshape(input_, shape=[-1, 2048])\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrn(x, radius, alpha, beta, name, bias=1.0):\n",
    "    return tf.nn.local_response_normalization(x, depth_radius = radius,\n",
    "                                            alpha = alpha, beta = beta,\n",
    "                                            bias = bias, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet:\n",
    "    def __init__(self, class_count, save_dir, save_path, batch_size):\n",
    "        self.class_count = class_count\n",
    "        self.save_dir = save_dir\n",
    "        self.save_path = save_path\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def _create_placeholders(self):\n",
    "        with tf.name_scope(\"data\"):\n",
    "            self.ims = tf.placeholder(shape=[None, 32, 32, 3], dtype=tf.float32, name=\"x\")\n",
    "            self.y_true = tf.placeholder(shape=[None, self.class_count], dtype=tf.float32, name=\"y\")\n",
    "            self.global_step = tf.Variable(initial_value=0,\n",
    "                          name='global_step', trainable=False)\n",
    "        \n",
    "    def _create_layers(self):\n",
    "        #layer1: convolution 11x11 + RELU:\n",
    "        with tf.name_scope(\"layer1\"):\n",
    "            layer1_1_conv = conv2d(self.x, 48, 11, 11, 3, [1, 4, 4, 1])\n",
    "            layer1_2_conv = conv2d(self.x, 48, 11, 11, 3, [1, 4, 4, 1])\n",
    "            norm1_1 = lrn(layer1_1_conv, 2, 2e-05, 0.75, name = 'norm1')\n",
    "            norm1_2 = lrn(layer1_2_conv, 2, 2e-05, 0.75, name = 'norm1')\n",
    "            layer1_1_pooling = max_pool(norm1_1, [1, 3, 3, 1], [1, 2, 2, 1])\n",
    "            layer1_2_pooling = max_pool(norm1_2, [1, 3, 3, 1], [1, 2, 2, 1])\n",
    "        \n",
    "        with tf.name_scope(\"layer2\"):\n",
    "            layer2_1_conv = conv2d(layer1_1_pooling, 128, 5, 5, 48, [1, 1, 1, 1])\n",
    "            layer2_2_conv = conv2d(layer1_2_pooling, 128, 5, 5, 48, [1, 1, 1, 1])\n",
    "            norm1_1 = lrn(layer2_1_conv, 2, 2e-05, 0.75, name = 'norm1')\n",
    "            norm1_2 = lrn(layer2_2_conv, 2, 2e-05, 0.75, name = 'norm1')            \n",
    "            layer2_1_pooling = max_pool(norm1_1, [1, 3, 3, 1], [1, 2, 2, 1])\n",
    "            layer2_2_pooling = max_pool(norm1_2, [1, 3, 3, 1], [1, 2, 2, 1])\n",
    "        \n",
    "        with tf.name_scope(\"layer3\"):\n",
    "            layer3_input = tf.nn.relu(tf.add(layer2_1_pooling, layer2_2_pooling))\n",
    "            layer3_1_conv = conv2d(layer3_input, 192, 3, 3, 128, [1, 1, 1, 1])\n",
    "            layer3_2_conv = conv2d(layer3_input, 192, 3, 3, 128, [1, 1, 1, 1])\n",
    "            \n",
    "        with tf.name_scope(\"layer4\"):\n",
    "            layer4_1_conv = conv2d(layer3_1_conv, 128, 3, 3, 192, [1, 1, 1, 1])\n",
    "            layer4_2_conv = conv2d(layer3_2_conv, 128, 3, 3, 192, [1, 1, 1, 1])\n",
    "            \n",
    "        with tf.name_scope(\"layer5\"):\n",
    "            layer5_1_conv = conv2d(layer4_1_conv, 2048, 3, 3, 128, [1, 1, 1, 1])\n",
    "            layer5_2_conv = conv2d(layer4_2_conv, 2048, 3, 3, 128, [1, 1, 1, 1])\n",
    "            layer5_1_pooling = max_pool(layer5_1_conv, [1, 3, 3, 1], [1, 2, 2, 1])\n",
    "            layer5_2_pooling = max_pool(layer5_2_conv, [1, 3, 3, 1], [1, 2, 2, 1])\n",
    "        \n",
    "        with tf.name_scope(\"layer6\"):\n",
    "            layer6_1_flatten = flatten(layer5_1_pooling)\n",
    "            layer6_2_flatten = flatten(layer5_2_pooling)\n",
    "            layer6_1_fc = fc(layer6_1_flatten, 2048, 2048, 1)\n",
    "            layer6_2_fc = fc(layer6_2_flatten, 2048, 2048, 1)\n",
    "            \n",
    "        with tf.name_scope(\"layer7\"):\n",
    "            layer7_1_fc = fc(layer6_1_fc, 2048, 2048, 1)\n",
    "            layer7_2_fc = fc(layer6_2_fc, 2048, 2048, 1)\n",
    "            \n",
    "        with tf.name_scope(\"layer8\"):\n",
    "            w_out = weight_variable([2048, self.class_count], \"weight_out\")\n",
    "            b_out = weight_variable([self.class_count], \"bias_out\")\n",
    "            self.logits = tf.add(tf.matmul(tf.nn.relu(layer7_1_fc + layer7_2_fc), w_out), b_out)        \n",
    "    \n",
    "    def _create_loss(self):\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            self.cross_entropy = tf.reduce_mean(\n",
    "                tf.nn.softmax_cross_entropy_with_logits(labels=self.y_true, logits=self.logits))   \n",
    "    \n",
    "    def _create_optimizer(self):\n",
    "        with tf.name_scope(\"optimizer\"):\n",
    "            self.train_step = tf.train.AdamOptimizer(1e-4).minimize(self.cross_entropy, global_step=self.global_step)\n",
    "            \n",
    "    def build_graph(self):\n",
    "        self._create_placeholders()\n",
    "        self.x = pre_process(self.ims, training=True)\n",
    "        self._create_layers()\n",
    "        self._create_loss()\n",
    "        self._create_optimizer()\n",
    "        self.saver = tf.train.Saver()\n",
    "    \n",
    "    def random_batch(self, images_train, labels_train):\n",
    "        # Number of images in the training-set.\n",
    "        num_images = len(images_train)\n",
    "\n",
    "        # Create a random index.\n",
    "        idx = np.random.choice(num_images,\n",
    "                               size=self.batch_size,\n",
    "                               replace=False)\n",
    "\n",
    "        # Use the random index to select random images and labels.\n",
    "        x_batch = images_train[idx, :, :, :]\n",
    "        y_batch = labels_train[idx, :]\n",
    "        return x_batch, y_batch\n",
    "    \n",
    "    def restore_checkpoints(self, session):\n",
    "        try:\n",
    "            print(\"Trying to restore last checkpoint ...\")\n",
    "\n",
    "            # Use TensorFlow to find the latest checkpoint - if any.\n",
    "            last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=self.save_dir)\n",
    "\n",
    "            # Try and load the data in the checkpoint.\n",
    "            self.saver.restore(session, save_path=last_chk_path)\n",
    "\n",
    "            # If we get to this point, the checkpoint was successfully loaded.\n",
    "            print(\"Restored checkpoint from:\", last_chk_path)\n",
    "        except:\n",
    "#             If the above failed for some reason, simply\n",
    "#             initialize all the variables for the TensorFlow graph.\n",
    "            print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "            session.run(tf.global_variables_initializer())    \n",
    "    \n",
    "    def train_model(self, images_train, labels_train, num_iterations):\n",
    "        y_pred = tf.nn.softmax(self.logits)\n",
    "        y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "        correct_prediction = tf.equal(y_pred_cls, tf.argmax(self.y_true, axis=1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.allow_growth = True\n",
    "\n",
    "        with tf.Session(config=config) as session:\n",
    "            self.restore_checkpoints(session)\n",
    "\n",
    "#             # Start-time used for printing time-usage below.        \n",
    "            start_time = time.time()\n",
    "        \n",
    "            for i in range(num_iterations):\n",
    "#                 # Get a batch of training examples.\n",
    "#                 # x_batch now holds a batch of images and\n",
    "#                 # y_true_batch are the true labels for those images.\n",
    "                x_batch, y_true_batch = self.random_batch(images_train, labels_train)\n",
    "                \n",
    "#                 # Put the batch into a dict with the proper names\n",
    "#                 # for placeholder variables in the TensorFlow graph.\n",
    "                feed_dict_train = {self.ims: x_batch,\n",
    "                                   self.y_true: y_true_batch}\n",
    "\n",
    "#                 # Run the optimizer using this batch of training data.\n",
    "#                 # TensorFlow assigns the variables in feed_dict_train\n",
    "#                 # to the placeholder variables and then runs the optimizer.\n",
    "#                 # We also want to retrieve the global_step counter.\n",
    "                i_global, _ , entropy = session.run([self.global_step, self.train_step, self.cross_entropy],\n",
    "                                          feed_dict=feed_dict_train)\n",
    "\n",
    "#                 # Print status to screen every 100 iterations (and last).\n",
    "                if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "#                     # Calculate the accuracy on the training-batch.\n",
    "                    batch_acc, entropy = session.run([accuracy, self.cross_entropy],\n",
    "                                            feed_dict=feed_dict_train)\n",
    "\n",
    "#                     # Print status.\n",
    "                    msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "                    print(msg.format(i_global, batch_acc))\n",
    "                    print(entropy)\n",
    "\n",
    "                # Save a checkpoint to disk every 1000 iterations (and last).\n",
    "                if (i_global % 1000 == 0) or (i == num_iterations - 1):\n",
    "                    # Save all variables of the TensorFlow graph to a\n",
    "                    # checkpoint. Append the global_step counter\n",
    "                    # to the filename so we save the last several checkpoints.\n",
    "                    self.saver.save(session,\n",
    "                               save_path=self.save_path,\n",
    "                               global_step=self.global_step)\n",
    "\n",
    "                    print(\"Saved checkpoint.\")\n",
    "            \n",
    "            self.print_test_accuracy(session)\n",
    "\n",
    "            # Ending time.\n",
    "            end_time = time.time()\n",
    "\n",
    "            # Difference between start and end-times.\n",
    "            time_dif = end_time - start_time\n",
    "\n",
    "            # Print the time-usage.\n",
    "            print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "            \n",
    "    def predict_cls(self, session, images, labels, cls_true):\n",
    "        batch_size = 128\n",
    "\n",
    "        # Number of images.\n",
    "        num_images = len(images)\n",
    "\n",
    "        # Allocate an array for the predicted classes which\n",
    "        # will be calculated in batches and filled into this array.\n",
    "        cls_pred = np.zeros(shape=num_images, dtype=np.int)\n",
    "\n",
    "        # Now calculate the predicted classes for the batches.\n",
    "        # We will just iterate through all the batches.\n",
    "        # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "        # The starting index for the next batch is denoted i.\n",
    "        i = 0\n",
    "\n",
    "        while i < num_images:\n",
    "            # The ending index for the next batch is denoted j.\n",
    "            j = min(i + batch_size, num_images)\n",
    "\n",
    "            # Create a feed-dict with the images and labels\n",
    "            # between index i and j.\n",
    "            \n",
    "            self.batch_size = j - i + 1\n",
    "            \n",
    "            feed_dict = {self.x: images[i:j, :],\n",
    "                         self.y_true: labels[i:j, :]}\n",
    "\n",
    "            # Calculate the predicted class using TensorFlow.\n",
    "            y_pred = tf.nn.softmax(alexNet.logits)\n",
    "            y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "            cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "\n",
    "            # Set the start-index for the next batch to the\n",
    "            # end-index of the current batch.\n",
    "            i = j\n",
    "\n",
    "        # Create a boolean array whether each image is correctly classified.\n",
    "        correct = (cls_true == cls_pred)\n",
    "\n",
    "        return correct, cls_pred\n",
    "\n",
    "    def predict_cls_test(self, session):\n",
    "        return self.predict_cls(session, images = images_test,\n",
    "                           labels = labels_test,\n",
    "                           cls_true = cls_test)\n",
    "    \n",
    "    def classification_accuracy(self, correct):\n",
    "        # When averaging a boolean array, False means 0 and True means 1.\n",
    "        # So we are calculating: number of True / len(correct) which is\n",
    "        # the same as the classification accuracy.\n",
    "\n",
    "        # Return the classification accuracy\n",
    "        # and the number of correct classifications.\n",
    "        return correct.mean(), correct.sum()\n",
    "    \n",
    "    def print_test_accuracy(self, session, show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "\n",
    "        # For all the images in the test-set,\n",
    "        # calculate the predicted classes and whether they are correct.\n",
    "        correct, cls_pred = self.predict_cls_test(session)\n",
    "\n",
    "        # Classification accuracy and the number of correct classifications.\n",
    "        acc, num_correct = self.classification_accuracy(correct)\n",
    "\n",
    "        # Number of images being classified.\n",
    "        num_images = len(correct)\n",
    "\n",
    "        # Print the accuracy.\n",
    "        msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "        print(msg.format(acc, num_correct, num_images))\n",
    "\n",
    "        # Plot some examples of mis-classifications, if desired.\n",
    "        if show_example_errors:\n",
    "            print(\"Example errors:\")\n",
    "            plot_example_errors(cls_pred=cls_pred, correct=correct)\n",
    "\n",
    "        # Plot the confusion matrix, if desired.\n",
    "        if show_confusion_matrix:\n",
    "            print(\"Confusion Matrix:\")\n",
    "            plot_confusion_matrix(cls_pred=cls_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints_alexNet/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_path = os.path.join(save_dir, 'cifar10_cnn')\n",
    "\n",
    "alexNet = AlexNet(len(class_names), save_dir, save_path, 128)\n",
    "alexNet.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_alexNet/cifar10_cnn-1000\n",
      "Restored checkpoint from: checkpoints_alexNet/cifar10_cnn-1000\n",
      "Global Step:   1100, Training Batch Accuracy:  29.4%\n",
      "47.735\n",
      "Global Step:   1200, Training Batch Accuracy:  29.4%\n",
      "60.9607\n",
      "Global Step:   1300, Training Batch Accuracy:  29.4%\n",
      "39.3841\n",
      "Global Step:   1400, Training Batch Accuracy:  35.3%\n",
      "19.1757\n",
      "Global Step:   1500, Training Batch Accuracy:  23.5%\n",
      "20.5704\n",
      "Global Step:   1600, Training Batch Accuracy:  29.4%\n",
      "18.1247\n",
      "Global Step:   1700, Training Batch Accuracy:  41.2%\n",
      "16.4039\n",
      "Global Step:   1800, Training Batch Accuracy:  29.4%\n",
      "15.7346\n",
      "Global Step:   1900, Training Batch Accuracy:  41.2%\n",
      "9.91651\n",
      "Global Step:   2000, Training Batch Accuracy:  29.4%\n",
      "15.5065\n",
      "Saved checkpoint.\n",
      "Global Step:   2100, Training Batch Accuracy:  23.5%\n",
      "8.51555\n",
      "Global Step:   2200, Training Batch Accuracy:  35.3%\n",
      "10.1586\n",
      "Global Step:   2300, Training Batch Accuracy:  29.4%\n",
      "12.225\n",
      "Global Step:   2400, Training Batch Accuracy:  23.5%\n",
      "6.72022\n",
      "Global Step:   2500, Training Batch Accuracy:  17.6%\n",
      "7.94944\n",
      "Global Step:   2600, Training Batch Accuracy:  11.8%\n",
      "5.26174\n",
      "Global Step:   2700, Training Batch Accuracy:  23.5%\n",
      "2.59744\n",
      "Global Step:   2800, Training Batch Accuracy:   0.0%\n",
      "4.46355\n",
      "Global Step:   2900, Training Batch Accuracy:  23.5%\n",
      "3.81659\n",
      "Global Step:   3000, Training Batch Accuracy:  35.3%\n",
      "2.70485\n",
      "Saved checkpoint.\n",
      "Global Step:   3100, Training Batch Accuracy:  23.5%\n",
      "2.41186\n",
      "Global Step:   3200, Training Batch Accuracy:   0.0%\n",
      "2.58708\n",
      "Global Step:   3300, Training Batch Accuracy:  17.6%\n",
      "2.4026\n",
      "Global Step:   3400, Training Batch Accuracy:  41.2%\n",
      "2.16535\n",
      "Global Step:   3500, Training Batch Accuracy:  35.3%\n",
      "2.08126\n",
      "Global Step:   3600, Training Batch Accuracy:  29.4%\n",
      "2.61252\n",
      "Global Step:   3700, Training Batch Accuracy:  17.6%\n",
      "2.31461\n",
      "Global Step:   3800, Training Batch Accuracy:  11.8%\n",
      "2.37409\n",
      "Global Step:   3900, Training Batch Accuracy:  23.5%\n",
      "2.36168\n",
      "Global Step:   4000, Training Batch Accuracy:  23.5%\n",
      "2.8855\n",
      "Saved checkpoint.\n",
      "Global Step:   4100, Training Batch Accuracy:  29.4%\n",
      "3.22305\n",
      "Global Step:   4200, Training Batch Accuracy:  35.3%\n",
      "2.40432\n",
      "Global Step:   4300, Training Batch Accuracy:  11.8%\n",
      "2.61888\n",
      "Global Step:   4400, Training Batch Accuracy:  23.5%\n",
      "2.67302\n",
      "Global Step:   4500, Training Batch Accuracy:   5.9%\n",
      "3.04105\n",
      "Global Step:   4600, Training Batch Accuracy:  35.3%\n",
      "4.37715\n",
      "Global Step:   4700, Training Batch Accuracy:  17.6%\n",
      "2.49997\n",
      "Global Step:   4800, Training Batch Accuracy:  11.8%\n",
      "2.73294\n",
      "Global Step:   4900, Training Batch Accuracy:  11.8%\n",
      "2.57115\n",
      "Global Step:   5000, Training Batch Accuracy:  23.5%\n",
      "2.37245\n",
      "Saved checkpoint.\n",
      "Global Step:   5100, Training Batch Accuracy:  11.8%\n",
      "2.67161\n",
      "Global Step:   5200, Training Batch Accuracy:  29.4%\n",
      "2.53297\n",
      "Global Step:   5300, Training Batch Accuracy:  17.6%\n",
      "3.44831\n",
      "Global Step:   5400, Training Batch Accuracy:  17.6%\n",
      "3.29955\n",
      "Global Step:   5500, Training Batch Accuracy:  17.6%\n",
      "4.18043\n",
      "Global Step:   5600, Training Batch Accuracy:  11.8%\n",
      "3.01535\n",
      "Global Step:   5700, Training Batch Accuracy:  11.8%\n",
      "2.8399\n",
      "Global Step:   5800, Training Batch Accuracy:  23.5%\n",
      "2.6886\n",
      "Global Step:   5900, Training Batch Accuracy:  11.8%\n",
      "3.75419\n",
      "Global Step:   6000, Training Batch Accuracy:  11.8%\n",
      "2.32211\n",
      "Saved checkpoint.\n",
      "Global Step:   6100, Training Batch Accuracy:  29.4%\n",
      "2.52164\n",
      "Global Step:   6200, Training Batch Accuracy:  35.3%\n",
      "2.88691\n",
      "Global Step:   6300, Training Batch Accuracy:  23.5%\n",
      "2.68097\n",
      "Global Step:   6400, Training Batch Accuracy:  23.5%\n",
      "3.3416\n",
      "Global Step:   6500, Training Batch Accuracy:   0.0%\n",
      "2.94297\n",
      "Global Step:   6600, Training Batch Accuracy:   5.9%\n",
      "3.81962\n",
      "Global Step:   6700, Training Batch Accuracy:  17.6%\n",
      "2.84116\n",
      "Global Step:   6800, Training Batch Accuracy:  23.5%\n",
      "2.36967\n",
      "Global Step:   6900, Training Batch Accuracy:  11.8%\n",
      "2.44682\n",
      "Global Step:   7000, Training Batch Accuracy:  11.8%\n",
      "3.80756\n",
      "Saved checkpoint.\n",
      "Global Step:   7100, Training Batch Accuracy:  35.3%\n",
      "3.25672\n",
      "Global Step:   7200, Training Batch Accuracy:  41.2%\n",
      "2.35783\n",
      "Global Step:   7300, Training Batch Accuracy:  23.5%\n",
      "2.53535\n",
      "Global Step:   7400, Training Batch Accuracy:  23.5%\n",
      "2.3418\n",
      "Global Step:   7500, Training Batch Accuracy:  11.8%\n",
      "3.42967\n",
      "Global Step:   7600, Training Batch Accuracy:   5.9%\n",
      "3.3136\n",
      "Global Step:   7700, Training Batch Accuracy:  17.6%\n",
      "2.22166\n",
      "Global Step:   7800, Training Batch Accuracy:  23.5%\n",
      "3.13541\n",
      "Global Step:   7900, Training Batch Accuracy:  35.3%\n",
      "1.99514\n",
      "Global Step:   8000, Training Batch Accuracy:  35.3%\n",
      "2.3391\n",
      "Saved checkpoint.\n",
      "Global Step:   8100, Training Batch Accuracy:  23.5%\n",
      "3.12545\n",
      "Global Step:   8200, Training Batch Accuracy:  29.4%\n",
      "2.51438\n",
      "Global Step:   8300, Training Batch Accuracy:   0.0%\n",
      "3.6754\n",
      "Global Step:   8400, Training Batch Accuracy:  29.4%\n",
      "1.9317\n",
      "Global Step:   8500, Training Batch Accuracy:  11.8%\n",
      "3.38232\n",
      "Global Step:   8600, Training Batch Accuracy:  23.5%\n",
      "4.73823\n",
      "Global Step:   8700, Training Batch Accuracy:  11.8%\n",
      "3.28189\n",
      "Global Step:   8800, Training Batch Accuracy:  11.8%\n",
      "2.70805\n",
      "Global Step:   8900, Training Batch Accuracy:  17.6%\n",
      "2.80356\n",
      "Global Step:   9000, Training Batch Accuracy:  23.5%\n",
      "3.1274\n",
      "Saved checkpoint.\n",
      "Global Step:   9100, Training Batch Accuracy:  35.3%\n",
      "2.0525\n",
      "Global Step:   9200, Training Batch Accuracy:  35.3%\n",
      "2.94614\n",
      "Global Step:   9300, Training Batch Accuracy:  47.1%\n",
      "1.95214\n",
      "Global Step:   9400, Training Batch Accuracy:  29.4%\n",
      "2.95659\n",
      "Global Step:   9500, Training Batch Accuracy:  11.8%\n",
      "2.47501\n",
      "Global Step:   9600, Training Batch Accuracy:   5.9%\n",
      "2.8537\n",
      "Global Step:   9700, Training Batch Accuracy:  17.6%\n",
      "5.19861\n",
      "Global Step:   9800, Training Batch Accuracy:  41.2%\n",
      "1.70027\n",
      "Global Step:   9900, Training Batch Accuracy:  17.6%\n",
      "3.11384\n",
      "Global Step:  10000, Training Batch Accuracy:  11.8%\n",
      "3.24913\n",
      "Saved checkpoint.\n",
      "Global Step:  10100, Training Batch Accuracy:  11.8%\n",
      "2.47221\n",
      "Global Step:  10200, Training Batch Accuracy:  35.3%\n",
      "1.72655\n",
      "Global Step:  10300, Training Batch Accuracy:  11.8%\n",
      "2.26131\n",
      "Global Step:  10400, Training Batch Accuracy:  17.6%\n",
      "2.39091\n",
      "Global Step:  10500, Training Batch Accuracy:  23.5%\n",
      "2.12252\n",
      "Global Step:  10600, Training Batch Accuracy:  23.5%\n",
      "2.89672\n",
      "Global Step:  10700, Training Batch Accuracy:  17.6%\n",
      "3.01441\n",
      "Global Step:  10800, Training Batch Accuracy:  17.6%\n",
      "2.45196\n",
      "Global Step:  10900, Training Batch Accuracy:  23.5%\n",
      "2.05772\n",
      "Global Step:  11000, Training Batch Accuracy:  29.4%\n",
      "2.52157\n",
      "Saved checkpoint.\n",
      "Global Step:  11100, Training Batch Accuracy:  17.6%\n",
      "2.01759\n",
      "Global Step:  11200, Training Batch Accuracy:   5.9%\n",
      "2.65579\n",
      "Global Step:  11300, Training Batch Accuracy:  35.3%\n",
      "1.79412\n",
      "Global Step:  11400, Training Batch Accuracy:  11.8%\n",
      "2.42176\n",
      "Global Step:  11500, Training Batch Accuracy:  23.5%\n",
      "3.12752\n",
      "Global Step:  11600, Training Batch Accuracy:  17.6%\n",
      "2.29435\n",
      "Global Step:  11700, Training Batch Accuracy:  23.5%\n",
      "2.26413\n",
      "Global Step:  11800, Training Batch Accuracy:  29.4%\n",
      "2.41278\n",
      "Global Step:  11900, Training Batch Accuracy:  17.6%\n",
      "2.35004\n",
      "Global Step:  12000, Training Batch Accuracy:  17.6%\n",
      "2.10361\n",
      "Saved checkpoint.\n",
      "Global Step:  12100, Training Batch Accuracy:  35.3%\n",
      "1.78792\n",
      "Global Step:  12200, Training Batch Accuracy:  11.8%\n",
      "2.29664\n",
      "Global Step:  12300, Training Batch Accuracy:  47.1%\n",
      "1.55306\n",
      "Global Step:  12400, Training Batch Accuracy:  29.4%\n",
      "1.7674\n",
      "Global Step:  12500, Training Batch Accuracy:  17.6%\n",
      "2.28054\n",
      "Global Step:  12600, Training Batch Accuracy:  17.6%\n",
      "2.30071\n",
      "Global Step:  12700, Training Batch Accuracy:  29.4%\n",
      "2.23667\n",
      "Global Step:  12800, Training Batch Accuracy:  29.4%\n",
      "1.8777\n",
      "Global Step:  12900, Training Batch Accuracy:  29.4%\n",
      "2.02398\n",
      "Global Step:  13000, Training Batch Accuracy:  23.5%\n",
      "2.51285\n",
      "Saved checkpoint.\n",
      "Global Step:  13100, Training Batch Accuracy:  29.4%\n",
      "1.77409\n",
      "Global Step:  13200, Training Batch Accuracy:  17.6%\n",
      "2.2306\n",
      "Global Step:  13300, Training Batch Accuracy:  17.6%\n",
      "2.37195\n",
      "Global Step:  13400, Training Batch Accuracy:  17.6%\n",
      "2.13431\n",
      "Global Step:  13500, Training Batch Accuracy:  35.3%\n",
      "1.65992\n",
      "Global Step:  13600, Training Batch Accuracy:  35.3%\n",
      "1.98459\n",
      "Global Step:  13700, Training Batch Accuracy:  17.6%\n",
      "1.92511\n",
      "Global Step:  13800, Training Batch Accuracy:  41.2%\n",
      "1.79477\n",
      "Global Step:  13900, Training Batch Accuracy:  29.4%\n",
      "2.13774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:  14000, Training Batch Accuracy:  17.6%\n",
      "2.11696\n",
      "Saved checkpoint.\n",
      "Global Step:  14100, Training Batch Accuracy:  29.4%\n",
      "1.85858\n",
      "Global Step:  14200, Training Batch Accuracy:  23.5%\n",
      "2.00325\n",
      "Global Step:  14300, Training Batch Accuracy:  35.3%\n",
      "2.06482\n",
      "Global Step:  14400, Training Batch Accuracy:  41.2%\n",
      "2.0965\n",
      "Global Step:  14500, Training Batch Accuracy:  23.5%\n",
      "1.75621\n",
      "Global Step:  14600, Training Batch Accuracy:  35.3%\n",
      "1.54923\n",
      "Global Step:  14700, Training Batch Accuracy:  23.5%\n",
      "1.84923\n",
      "Global Step:  14800, Training Batch Accuracy:  29.4%\n",
      "2.15459\n",
      "Global Step:  14900, Training Batch Accuracy:  17.6%\n",
      "1.97903\n",
      "Global Step:  15000, Training Batch Accuracy:  35.3%\n",
      "1.76519\n",
      "Saved checkpoint.\n",
      "Global Step:  15100, Training Batch Accuracy:  29.4%\n",
      "1.61297\n",
      "Global Step:  15200, Training Batch Accuracy:  17.6%\n",
      "1.93001\n",
      "Global Step:  15300, Training Batch Accuracy:  52.9%\n",
      "1.59976\n",
      "Global Step:  15400, Training Batch Accuracy:  11.8%\n",
      "2.11472\n",
      "Global Step:  15500, Training Batch Accuracy:  23.5%\n",
      "2.11483\n",
      "Global Step:  15600, Training Batch Accuracy:  23.5%\n",
      "2.15112\n",
      "Global Step:  15700, Training Batch Accuracy:  41.2%\n",
      "1.7599\n",
      "Global Step:  15800, Training Batch Accuracy:  41.2%\n",
      "1.97341\n",
      "Global Step:  15900, Training Batch Accuracy:  23.5%\n",
      "2.12721\n",
      "Global Step:  16000, Training Batch Accuracy:  29.4%\n",
      "1.5286\n",
      "Saved checkpoint.\n",
      "Global Step:  16100, Training Batch Accuracy:  35.3%\n",
      "1.78324\n",
      "Global Step:  16200, Training Batch Accuracy:  11.8%\n",
      "2.3167\n",
      "Global Step:  16300, Training Batch Accuracy:  47.1%\n",
      "1.7342\n",
      "Global Step:  16400, Training Batch Accuracy:  29.4%\n",
      "1.71543\n",
      "Global Step:  16500, Training Batch Accuracy:  11.8%\n",
      "2.12374\n",
      "Global Step:  16600, Training Batch Accuracy:  35.3%\n",
      "1.67085\n",
      "Global Step:  16700, Training Batch Accuracy:  29.4%\n",
      "2.2226\n",
      "Global Step:  16800, Training Batch Accuracy:  35.3%\n",
      "2.08068\n",
      "Global Step:  16900, Training Batch Accuracy:  29.4%\n",
      "1.7582\n",
      "Global Step:  17000, Training Batch Accuracy:  23.5%\n",
      "1.96157\n",
      "Saved checkpoint.\n",
      "Global Step:  17100, Training Batch Accuracy:  29.4%\n",
      "2.03563\n",
      "Global Step:  17200, Training Batch Accuracy:  23.5%\n",
      "1.9421\n",
      "Global Step:  17300, Training Batch Accuracy:  29.4%\n",
      "1.66581\n",
      "Global Step:  17400, Training Batch Accuracy:  11.8%\n",
      "2.31845\n",
      "Global Step:  17500, Training Batch Accuracy:  35.3%\n",
      "2.38634\n",
      "Global Step:  17600, Training Batch Accuracy:  41.2%\n",
      "1.61936\n",
      "Global Step:  17700, Training Batch Accuracy:  17.6%\n",
      "2.09978\n",
      "Global Step:  17800, Training Batch Accuracy:  23.5%\n",
      "1.88417\n",
      "Global Step:  17900, Training Batch Accuracy:  17.6%\n",
      "2.02594\n",
      "Global Step:  18000, Training Batch Accuracy:  47.1%\n",
      "1.52611\n",
      "Saved checkpoint.\n",
      "Global Step:  18100, Training Batch Accuracy:  17.6%\n",
      "2.11228\n",
      "Global Step:  18200, Training Batch Accuracy:  23.5%\n",
      "1.7099\n",
      "Global Step:  18300, Training Batch Accuracy:  41.2%\n",
      "1.71301\n",
      "Global Step:  18400, Training Batch Accuracy:  29.4%\n",
      "1.86295\n",
      "Global Step:  18500, Training Batch Accuracy:  52.9%\n",
      "1.38966\n",
      "Global Step:  18600, Training Batch Accuracy:  29.4%\n",
      "1.95004\n",
      "Global Step:  18700, Training Batch Accuracy:  11.8%\n",
      "2.59734\n",
      "Global Step:  18800, Training Batch Accuracy:  41.2%\n",
      "1.8576\n",
      "Global Step:  18900, Training Batch Accuracy:  17.6%\n",
      "2.28282\n",
      "Global Step:  19000, Training Batch Accuracy:  52.9%\n",
      "1.42156\n",
      "Saved checkpoint.\n",
      "Global Step:  19100, Training Batch Accuracy:  29.4%\n",
      "1.84312\n",
      "Global Step:  19200, Training Batch Accuracy:  35.3%\n",
      "1.66205\n",
      "Global Step:  19300, Training Batch Accuracy:  29.4%\n",
      "1.9196\n",
      "Global Step:  19400, Training Batch Accuracy:  35.3%\n",
      "1.98994\n",
      "Global Step:  19500, Training Batch Accuracy:  41.2%\n",
      "1.72216\n",
      "Global Step:  19600, Training Batch Accuracy:  23.5%\n",
      "1.94942\n",
      "Global Step:  19700, Training Batch Accuracy:  47.1%\n",
      "1.50977\n",
      "Global Step:  19800, Training Batch Accuracy:  17.6%\n",
      "1.83734\n",
      "Global Step:  19900, Training Batch Accuracy:  35.3%\n",
      "2.00857\n",
      "Global Step:  20000, Training Batch Accuracy:  23.5%\n",
      "2.29696\n",
      "Saved checkpoint.\n",
      "Global Step:  20100, Training Batch Accuracy:  11.8%\n",
      "2.27591\n",
      "Global Step:  20200, Training Batch Accuracy:  35.3%\n",
      "1.92616\n",
      "Global Step:  20300, Training Batch Accuracy:  17.6%\n",
      "2.01459\n",
      "Global Step:  20400, Training Batch Accuracy:  35.3%\n",
      "1.71132\n",
      "Global Step:  20500, Training Batch Accuracy:  23.5%\n",
      "1.80865\n",
      "Global Step:  20600, Training Batch Accuracy:  17.6%\n",
      "1.9101\n",
      "Global Step:  20700, Training Batch Accuracy:  41.2%\n",
      "1.53429\n",
      "Global Step:  20800, Training Batch Accuracy:  11.8%\n",
      "2.18522\n",
      "Global Step:  20900, Training Batch Accuracy:  17.6%\n",
      "2.1403\n",
      "Global Step:  21000, Training Batch Accuracy:  29.4%\n",
      "1.66773\n",
      "Saved checkpoint.\n",
      "Global Step:  21100, Training Batch Accuracy:  47.1%\n",
      "1.58695\n",
      "Global Step:  21200, Training Batch Accuracy:  23.5%\n",
      "1.9781\n",
      "Global Step:  21300, Training Batch Accuracy:  23.5%\n",
      "1.91421\n",
      "Global Step:  21400, Training Batch Accuracy:  11.8%\n",
      "2.32\n",
      "Global Step:  21500, Training Batch Accuracy:  47.1%\n",
      "1.62401\n",
      "Global Step:  21600, Training Batch Accuracy:  35.3%\n",
      "1.53138\n",
      "Global Step:  21700, Training Batch Accuracy:  58.8%\n",
      "1.43815\n",
      "Global Step:  21800, Training Batch Accuracy:  17.6%\n",
      "1.78163\n",
      "Global Step:  21900, Training Batch Accuracy:  17.6%\n",
      "1.71762\n",
      "Global Step:  22000, Training Batch Accuracy:  35.3%\n",
      "1.55767\n",
      "Saved checkpoint.\n",
      "Global Step:  22100, Training Batch Accuracy:  35.3%\n",
      "1.63811\n",
      "Global Step:  22200, Training Batch Accuracy:  35.3%\n",
      "1.79449\n",
      "Global Step:  22300, Training Batch Accuracy:  23.5%\n",
      "1.62723\n",
      "Global Step:  22400, Training Batch Accuracy:  23.5%\n",
      "1.81125\n",
      "Global Step:  22500, Training Batch Accuracy:  52.9%\n",
      "1.75235\n",
      "Global Step:  22600, Training Batch Accuracy:  41.2%\n",
      "1.3919\n",
      "Global Step:  22700, Training Batch Accuracy:  23.5%\n",
      "1.90926\n",
      "Global Step:  22800, Training Batch Accuracy:  23.5%\n",
      "1.9914\n",
      "Global Step:  22900, Training Batch Accuracy:  17.6%\n",
      "2.34269\n",
      "Global Step:  23000, Training Batch Accuracy:  35.3%\n",
      "1.73391\n",
      "Saved checkpoint.\n",
      "Global Step:  23100, Training Batch Accuracy:  29.4%\n",
      "2.04046\n",
      "Global Step:  23200, Training Batch Accuracy:  35.3%\n",
      "2.00549\n",
      "Global Step:  23300, Training Batch Accuracy:  35.3%\n",
      "2.07026\n",
      "Global Step:  23400, Training Batch Accuracy:  52.9%\n",
      "1.42322\n",
      "Global Step:  23500, Training Batch Accuracy:  35.3%\n",
      "1.89192\n",
      "Global Step:  23600, Training Batch Accuracy:  47.1%\n",
      "1.52826\n",
      "Global Step:  23700, Training Batch Accuracy:  29.4%\n",
      "1.8028\n",
      "Global Step:  23800, Training Batch Accuracy:  23.5%\n",
      "2.06513\n",
      "Global Step:  23900, Training Batch Accuracy:  41.2%\n",
      "1.61257\n",
      "Global Step:  24000, Training Batch Accuracy:  35.3%\n",
      "1.90763\n",
      "Saved checkpoint.\n",
      "Global Step:  24100, Training Batch Accuracy:  23.5%\n",
      "1.87337\n",
      "Global Step:  24200, Training Batch Accuracy:  29.4%\n",
      "1.83063\n",
      "Global Step:  24300, Training Batch Accuracy:  47.1%\n",
      "1.39428\n",
      "Global Step:  24400, Training Batch Accuracy:  52.9%\n",
      "1.40957\n",
      "Global Step:  24500, Training Batch Accuracy:  17.6%\n",
      "1.93243\n",
      "Global Step:  24600, Training Batch Accuracy:  29.4%\n",
      "1.68679\n",
      "Global Step:  24700, Training Batch Accuracy:  29.4%\n",
      "2.21542\n",
      "Global Step:  24800, Training Batch Accuracy:  29.4%\n",
      "1.71675\n",
      "Global Step:  24900, Training Batch Accuracy:  47.1%\n",
      "1.7172\n",
      "Global Step:  25000, Training Batch Accuracy:  41.2%\n",
      "1.50047\n",
      "Saved checkpoint.\n",
      "Global Step:  25100, Training Batch Accuracy:  41.2%\n",
      "1.6307\n",
      "Global Step:  25200, Training Batch Accuracy:  47.1%\n",
      "1.46663\n",
      "Global Step:  25300, Training Batch Accuracy:  47.1%\n",
      "1.45223\n",
      "Global Step:  25400, Training Batch Accuracy:  17.6%\n",
      "1.59328\n",
      "Global Step:  25500, Training Batch Accuracy:  17.6%\n",
      "1.77803\n",
      "Global Step:  25600, Training Batch Accuracy:  29.4%\n",
      "1.72987\n",
      "Global Step:  25700, Training Batch Accuracy:  29.4%\n",
      "2.05902\n",
      "Global Step:  25800, Training Batch Accuracy:  41.2%\n",
      "1.65181\n",
      "Global Step:  25900, Training Batch Accuracy:  35.3%\n",
      "1.60482\n",
      "Global Step:  26000, Training Batch Accuracy:  41.2%\n",
      "1.68466\n",
      "Saved checkpoint.\n",
      "Global Step:  26100, Training Batch Accuracy:  41.2%\n",
      "1.55048\n",
      "Global Step:  26200, Training Batch Accuracy:  35.3%\n",
      "1.48424\n",
      "Global Step:  26300, Training Batch Accuracy:  47.1%\n",
      "1.39585\n",
      "Global Step:  26400, Training Batch Accuracy:  41.2%\n",
      "1.40876\n",
      "Global Step:  26500, Training Batch Accuracy:  17.6%\n",
      "1.97058\n",
      "Global Step:  26600, Training Batch Accuracy:  17.6%\n",
      "1.8816\n",
      "Global Step:  26700, Training Batch Accuracy:  47.1%\n",
      "1.73484\n",
      "Global Step:  26800, Training Batch Accuracy:  47.1%\n",
      "1.28817\n",
      "Global Step:  26900, Training Batch Accuracy:  29.4%\n",
      "1.99428\n",
      "Global Step:  27000, Training Batch Accuracy:  35.3%\n",
      "1.49154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint.\n",
      "Global Step:  27100, Training Batch Accuracy:  64.7%\n",
      "1.24547\n",
      "Global Step:  27200, Training Batch Accuracy:  29.4%\n",
      "1.5544\n",
      "Global Step:  27300, Training Batch Accuracy:  47.1%\n",
      "1.43189\n",
      "Global Step:  27400, Training Batch Accuracy:  35.3%\n",
      "2.05217\n",
      "Global Step:  27500, Training Batch Accuracy:  47.1%\n",
      "1.6353\n",
      "Global Step:  27600, Training Batch Accuracy:  29.4%\n",
      "1.65828\n",
      "Global Step:  27700, Training Batch Accuracy:  29.4%\n",
      "1.93243\n",
      "Global Step:  27800, Training Batch Accuracy:  41.2%\n",
      "1.98951\n",
      "Global Step:  27900, Training Batch Accuracy:  58.8%\n",
      "0.984311\n",
      "Global Step:  28000, Training Batch Accuracy:  41.2%\n",
      "1.68987\n",
      "Saved checkpoint.\n",
      "Global Step:  28100, Training Batch Accuracy:  41.2%\n",
      "1.71802\n",
      "Global Step:  28200, Training Batch Accuracy:  47.1%\n",
      "1.62669\n",
      "Global Step:  28300, Training Batch Accuracy:  52.9%\n",
      "1.3884\n",
      "Global Step:  28400, Training Batch Accuracy:  35.3%\n",
      "1.87165\n",
      "Global Step:  28500, Training Batch Accuracy:  41.2%\n",
      "1.34226\n",
      "Global Step:  28600, Training Batch Accuracy:  29.4%\n",
      "1.86518\n",
      "Global Step:  28700, Training Batch Accuracy:  29.4%\n",
      "1.70572\n",
      "Global Step:  28800, Training Batch Accuracy:  70.6%\n",
      "1.33931\n",
      "Global Step:  28900, Training Batch Accuracy:  29.4%\n",
      "1.62043\n",
      "Global Step:  29000, Training Batch Accuracy:  52.9%\n",
      "1.35655\n",
      "Saved checkpoint.\n",
      "Global Step:  29100, Training Batch Accuracy:  41.2%\n",
      "1.53471\n",
      "Global Step:  29200, Training Batch Accuracy:  35.3%\n",
      "1.69904\n",
      "Global Step:  29300, Training Batch Accuracy:  52.9%\n",
      "1.47612\n",
      "Global Step:  29400, Training Batch Accuracy:  29.4%\n",
      "1.69829\n",
      "Global Step:  29500, Training Batch Accuracy:  17.6%\n",
      "1.74189\n",
      "Global Step:  29600, Training Batch Accuracy:  58.8%\n",
      "1.4373\n",
      "Global Step:  29700, Training Batch Accuracy:  41.2%\n",
      "1.41691\n",
      "Global Step:  29800, Training Batch Accuracy:  47.1%\n",
      "1.44594\n",
      "Global Step:  29900, Training Batch Accuracy:  41.2%\n",
      "1.50256\n",
      "Global Step:  30000, Training Batch Accuracy:  23.5%\n",
      "1.83108\n",
      "Saved checkpoint.\n",
      "Global Step:  30100, Training Batch Accuracy:  52.9%\n",
      "1.36269\n",
      "Global Step:  30200, Training Batch Accuracy:  35.3%\n",
      "1.48863\n",
      "Global Step:  30300, Training Batch Accuracy:  58.8%\n",
      "1.48827\n",
      "Global Step:  30400, Training Batch Accuracy:  35.3%\n",
      "1.3733\n",
      "Global Step:  30500, Training Batch Accuracy:  41.2%\n",
      "1.77491\n",
      "Global Step:  30600, Training Batch Accuracy:  41.2%\n",
      "1.45808\n",
      "Global Step:  30700, Training Batch Accuracy:  47.1%\n",
      "1.70666\n",
      "Global Step:  30800, Training Batch Accuracy:  35.3%\n",
      "1.74559\n",
      "Global Step:  30900, Training Batch Accuracy:  29.4%\n",
      "1.82453\n",
      "Global Step:  31000, Training Batch Accuracy:  41.2%\n",
      "1.77092\n",
      "Saved checkpoint.\n",
      "Global Step:  31100, Training Batch Accuracy:  47.1%\n",
      "1.22383\n",
      "Global Step:  31200, Training Batch Accuracy:  29.4%\n",
      "1.48496\n",
      "Global Step:  31300, Training Batch Accuracy:  29.4%\n",
      "1.82646\n",
      "Global Step:  31400, Training Batch Accuracy:  35.3%\n",
      "1.65858\n",
      "Global Step:  31500, Training Batch Accuracy:  41.2%\n",
      "1.70587\n",
      "Global Step:  31600, Training Batch Accuracy:  29.4%\n",
      "1.90288\n",
      "Global Step:  31700, Training Batch Accuracy:  29.4%\n",
      "1.7577\n",
      "Global Step:  31800, Training Batch Accuracy:  29.4%\n",
      "1.48696\n",
      "Global Step:  31900, Training Batch Accuracy:  41.2%\n",
      "1.69525\n",
      "Global Step:  32000, Training Batch Accuracy:  23.5%\n",
      "1.77745\n",
      "Saved checkpoint.\n",
      "Global Step:  32100, Training Batch Accuracy:  29.4%\n",
      "1.68312\n",
      "Global Step:  32200, Training Batch Accuracy:  29.4%\n",
      "1.80918\n",
      "Global Step:  32300, Training Batch Accuracy:  52.9%\n",
      "1.37289\n",
      "Global Step:  32400, Training Batch Accuracy:  47.1%\n",
      "1.33011\n",
      "Global Step:  32500, Training Batch Accuracy:  52.9%\n",
      "1.22681\n",
      "Global Step:  32600, Training Batch Accuracy:  29.4%\n",
      "1.64267\n",
      "Global Step:  32700, Training Batch Accuracy:  47.1%\n",
      "1.81308\n",
      "Global Step:  32800, Training Batch Accuracy:  23.5%\n",
      "1.81891\n",
      "Global Step:  32900, Training Batch Accuracy:  41.2%\n",
      "1.43041\n",
      "Global Step:  33000, Training Batch Accuracy:  47.1%\n",
      "1.5124\n",
      "Saved checkpoint.\n",
      "Global Step:  33100, Training Batch Accuracy:  29.4%\n",
      "1.83193\n",
      "Global Step:  33200, Training Batch Accuracy:  41.2%\n",
      "1.43684\n",
      "Global Step:  33300, Training Batch Accuracy:  47.1%\n",
      "1.50474\n",
      "Global Step:  33400, Training Batch Accuracy:  52.9%\n",
      "1.32666\n",
      "Global Step:  33500, Training Batch Accuracy:  58.8%\n",
      "1.25276\n",
      "Global Step:  33600, Training Batch Accuracy:  35.3%\n",
      "1.88504\n",
      "Global Step:  33700, Training Batch Accuracy:  35.3%\n",
      "1.57485\n",
      "Global Step:  33800, Training Batch Accuracy:  52.9%\n",
      "1.31127\n",
      "Global Step:  33900, Training Batch Accuracy:  47.1%\n",
      "1.22564\n",
      "Global Step:  34000, Training Batch Accuracy:  41.2%\n",
      "1.45193\n",
      "Saved checkpoint.\n",
      "Global Step:  34100, Training Batch Accuracy:  41.2%\n",
      "1.69774\n",
      "Global Step:  34200, Training Batch Accuracy:  47.1%\n",
      "1.42306\n",
      "Global Step:  34300, Training Batch Accuracy:  58.8%\n",
      "1.45009\n",
      "Global Step:  34400, Training Batch Accuracy:  23.5%\n",
      "1.87429\n",
      "Global Step:  34500, Training Batch Accuracy:  58.8%\n",
      "1.2701\n",
      "Global Step:  34600, Training Batch Accuracy:  47.1%\n",
      "1.53001\n",
      "Global Step:  34700, Training Batch Accuracy:  47.1%\n",
      "1.37231\n",
      "Global Step:  34800, Training Batch Accuracy:  11.8%\n",
      "2.04816\n",
      "Global Step:  34900, Training Batch Accuracy:  64.7%\n",
      "1.21161\n",
      "Global Step:  35000, Training Batch Accuracy:  64.7%\n",
      "1.29168\n",
      "Saved checkpoint.\n",
      "Global Step:  35100, Training Batch Accuracy:  52.9%\n",
      "1.37867\n",
      "Global Step:  35200, Training Batch Accuracy:  52.9%\n",
      "1.50236\n",
      "Global Step:  35300, Training Batch Accuracy:  52.9%\n",
      "1.4993\n",
      "Global Step:  35400, Training Batch Accuracy:  52.9%\n",
      "1.56444\n",
      "Global Step:  35500, Training Batch Accuracy:  35.3%\n",
      "1.54989\n",
      "Global Step:  35600, Training Batch Accuracy:  41.2%\n",
      "1.66891\n",
      "Global Step:  35700, Training Batch Accuracy:  52.9%\n",
      "1.62075\n",
      "Global Step:  35800, Training Batch Accuracy:  52.9%\n",
      "1.32345\n",
      "Global Step:  35900, Training Batch Accuracy:  41.2%\n",
      "1.50442\n",
      "Global Step:  36000, Training Batch Accuracy:  47.1%\n",
      "1.58032\n",
      "Saved checkpoint.\n",
      "Global Step:  36100, Training Batch Accuracy:  41.2%\n",
      "1.44108\n",
      "Global Step:  36200, Training Batch Accuracy:  70.6%\n",
      "0.98195\n",
      "Global Step:  36300, Training Batch Accuracy:  35.3%\n",
      "1.62711\n",
      "Global Step:  36400, Training Batch Accuracy:  35.3%\n",
      "1.43118\n",
      "Global Step:  36500, Training Batch Accuracy:  35.3%\n",
      "1.55393\n",
      "Global Step:  36600, Training Batch Accuracy:  52.9%\n",
      "1.24591\n",
      "Global Step:  36700, Training Batch Accuracy:  52.9%\n",
      "1.23228\n",
      "Global Step:  36800, Training Batch Accuracy:  52.9%\n",
      "1.22535\n",
      "Global Step:  36900, Training Batch Accuracy:  52.9%\n",
      "1.16067\n",
      "Global Step:  37000, Training Batch Accuracy:  47.1%\n",
      "1.40717\n",
      "Saved checkpoint.\n",
      "Global Step:  37100, Training Batch Accuracy:  58.8%\n",
      "1.56349\n",
      "Global Step:  37200, Training Batch Accuracy:  35.3%\n",
      "1.87771\n",
      "Global Step:  37300, Training Batch Accuracy:  29.4%\n",
      "1.57967\n",
      "Global Step:  37400, Training Batch Accuracy:  41.2%\n",
      "1.65086\n",
      "Global Step:  37500, Training Batch Accuracy:  52.9%\n",
      "1.18369\n",
      "Global Step:  37600, Training Batch Accuracy:  47.1%\n",
      "1.46409\n",
      "Global Step:  37700, Training Batch Accuracy:  41.2%\n",
      "1.84762\n",
      "Global Step:  37800, Training Batch Accuracy:  35.3%\n",
      "1.71446\n",
      "Global Step:  37900, Training Batch Accuracy:  47.1%\n",
      "1.6338\n",
      "Global Step:  38000, Training Batch Accuracy:  41.2%\n",
      "1.44991\n",
      "Saved checkpoint.\n",
      "Global Step:  38100, Training Batch Accuracy:  41.2%\n",
      "1.57902\n",
      "Global Step:  38200, Training Batch Accuracy:  47.1%\n",
      "1.75477\n",
      "Global Step:  38300, Training Batch Accuracy:  29.4%\n",
      "1.7333\n",
      "Global Step:  38400, Training Batch Accuracy:  58.8%\n",
      "1.66128\n",
      "Global Step:  38500, Training Batch Accuracy:  64.7%\n",
      "1.15364\n",
      "Global Step:  38600, Training Batch Accuracy:  41.2%\n",
      "1.73921\n",
      "Global Step:  38700, Training Batch Accuracy:  47.1%\n",
      "1.51732\n",
      "Global Step:  38800, Training Batch Accuracy:  70.6%\n",
      "0.957933\n",
      "Global Step:  38900, Training Batch Accuracy:  47.1%\n",
      "1.91656\n",
      "Global Step:  39000, Training Batch Accuracy:  23.5%\n",
      "1.67881\n",
      "Saved checkpoint.\n",
      "Global Step:  39100, Training Batch Accuracy:  47.1%\n",
      "1.69894\n",
      "Global Step:  39200, Training Batch Accuracy:  58.8%\n",
      "1.20192\n",
      "Global Step:  39300, Training Batch Accuracy:  41.2%\n",
      "1.49433\n",
      "Global Step:  39400, Training Batch Accuracy:  47.1%\n",
      "1.42839\n",
      "Global Step:  39500, Training Batch Accuracy:  47.1%\n",
      "1.44209\n",
      "Global Step:  39600, Training Batch Accuracy:  64.7%\n",
      "1.12199\n",
      "Global Step:  39700, Training Batch Accuracy:  58.8%\n",
      "1.77144\n",
      "Global Step:  39800, Training Batch Accuracy:  29.4%\n",
      "1.40582\n",
      "Global Step:  39900, Training Batch Accuracy:  47.1%\n",
      "1.53517\n",
      "Global Step:  40000, Training Batch Accuracy:  52.9%\n",
      "1.35064\n",
      "Saved checkpoint.\n",
      "Global Step:  40100, Training Batch Accuracy:  17.6%\n",
      "1.99798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:  40200, Training Batch Accuracy:  41.2%\n",
      "1.57849\n",
      "Global Step:  40300, Training Batch Accuracy:  23.5%\n",
      "1.69464\n",
      "Global Step:  40400, Training Batch Accuracy:  29.4%\n",
      "1.93997\n",
      "Global Step:  40500, Training Batch Accuracy:  58.8%\n",
      "1.18186\n",
      "Global Step:  40600, Training Batch Accuracy:  58.8%\n",
      "1.48913\n",
      "Global Step:  40700, Training Batch Accuracy:  29.4%\n",
      "1.62071\n",
      "Global Step:  40800, Training Batch Accuracy:  41.2%\n",
      "1.69666\n",
      "Global Step:  40900, Training Batch Accuracy:  58.8%\n",
      "1.55368\n",
      "Global Step:  41000, Training Batch Accuracy:  52.9%\n",
      "1.32566\n",
      "Saved checkpoint.\n",
      "Global Step:  41100, Training Batch Accuracy:  41.2%\n",
      "1.59799\n",
      "Global Step:  41200, Training Batch Accuracy:  47.1%\n",
      "1.33223\n",
      "Global Step:  41300, Training Batch Accuracy:  52.9%\n",
      "1.47584\n",
      "Global Step:  41400, Training Batch Accuracy:  35.3%\n",
      "1.66789\n",
      "Global Step:  41500, Training Batch Accuracy:  58.8%\n",
      "1.02276\n",
      "Global Step:  41600, Training Batch Accuracy:  35.3%\n",
      "1.54188\n",
      "Global Step:  41700, Training Batch Accuracy:  47.1%\n",
      "1.57467\n",
      "Global Step:  41800, Training Batch Accuracy:  47.1%\n",
      "1.78225\n",
      "Global Step:  41900, Training Batch Accuracy:  47.1%\n",
      "1.4917\n",
      "Global Step:  42000, Training Batch Accuracy:  41.2%\n",
      "1.40068\n",
      "Saved checkpoint.\n",
      "Global Step:  42100, Training Batch Accuracy:  35.3%\n",
      "1.48045\n",
      "Global Step:  42200, Training Batch Accuracy:  41.2%\n",
      "1.80162\n",
      "Global Step:  42300, Training Batch Accuracy:  47.1%\n",
      "1.49733\n",
      "Global Step:  42400, Training Batch Accuracy:  52.9%\n",
      "0.923112\n",
      "Global Step:  42500, Training Batch Accuracy:  35.3%\n",
      "1.39854\n",
      "Global Step:  42600, Training Batch Accuracy:  47.1%\n",
      "1.47392\n",
      "Global Step:  42700, Training Batch Accuracy:  35.3%\n",
      "1.41232\n",
      "Global Step:  42800, Training Batch Accuracy:  41.2%\n",
      "1.63998\n",
      "Global Step:  42900, Training Batch Accuracy:  52.9%\n",
      "1.54032\n",
      "Global Step:  43000, Training Batch Accuracy:  41.2%\n",
      "1.51139\n",
      "Saved checkpoint.\n",
      "Global Step:  43100, Training Batch Accuracy:  29.4%\n",
      "1.49439\n",
      "Global Step:  43200, Training Batch Accuracy:  41.2%\n",
      "1.56176\n",
      "Global Step:  43300, Training Batch Accuracy:  41.2%\n",
      "1.21092\n",
      "Global Step:  43400, Training Batch Accuracy:  58.8%\n",
      "1.13056\n",
      "Global Step:  43500, Training Batch Accuracy:  47.1%\n",
      "1.61013\n",
      "Global Step:  43600, Training Batch Accuracy:  47.1%\n",
      "1.33849\n",
      "Global Step:  43700, Training Batch Accuracy:  47.1%\n",
      "1.38944\n",
      "Global Step:  43800, Training Batch Accuracy:  41.2%\n",
      "1.6192\n",
      "Global Step:  43900, Training Batch Accuracy:  47.1%\n",
      "1.77795\n",
      "Global Step:  44000, Training Batch Accuracy:  29.4%\n",
      "1.7234\n",
      "Saved checkpoint.\n",
      "Global Step:  44100, Training Batch Accuracy:  35.3%\n",
      "1.12648\n",
      "Global Step:  44200, Training Batch Accuracy:  41.2%\n",
      "1.40765\n",
      "Global Step:  44300, Training Batch Accuracy:  47.1%\n",
      "1.33455\n",
      "Global Step:  44400, Training Batch Accuracy:  52.9%\n",
      "1.43709\n",
      "Global Step:  44500, Training Batch Accuracy:  29.4%\n",
      "1.53094\n",
      "Global Step:  44600, Training Batch Accuracy:  47.1%\n",
      "1.45534\n",
      "Global Step:  44700, Training Batch Accuracy:  70.6%\n",
      "0.887953\n",
      "Global Step:  44800, Training Batch Accuracy:  29.4%\n",
      "1.77827\n",
      "Global Step:  44900, Training Batch Accuracy:  58.8%\n",
      "1.39528\n",
      "Global Step:  45000, Training Batch Accuracy:  52.9%\n",
      "1.12654\n",
      "Saved checkpoint.\n",
      "Global Step:  45100, Training Batch Accuracy:  52.9%\n",
      "1.35089\n",
      "Global Step:  45200, Training Batch Accuracy:  64.7%\n",
      "1.35634\n",
      "Global Step:  45300, Training Batch Accuracy:  41.2%\n",
      "1.49914\n",
      "Global Step:  45400, Training Batch Accuracy:  52.9%\n",
      "1.34478\n",
      "Global Step:  45500, Training Batch Accuracy:  52.9%\n",
      "1.16743\n",
      "Global Step:  45600, Training Batch Accuracy:  64.7%\n",
      "1.00577\n",
      "Global Step:  45700, Training Batch Accuracy:  47.1%\n",
      "1.47634\n",
      "Global Step:  45800, Training Batch Accuracy:  29.4%\n",
      "1.58957\n",
      "Global Step:  45900, Training Batch Accuracy:  58.8%\n",
      "1.28967\n",
      "Global Step:  46000, Training Batch Accuracy:  58.8%\n",
      "1.15443\n",
      "Saved checkpoint.\n",
      "Global Step:  46100, Training Batch Accuracy:  23.5%\n",
      "2.25344\n",
      "Global Step:  46200, Training Batch Accuracy:  29.4%\n",
      "2.03612\n",
      "Global Step:  46300, Training Batch Accuracy:  47.1%\n",
      "1.4783\n",
      "Global Step:  46400, Training Batch Accuracy:  64.7%\n",
      "1.27827\n",
      "Global Step:  46500, Training Batch Accuracy:  64.7%\n",
      "1.07683\n",
      "Global Step:  46600, Training Batch Accuracy:  70.6%\n",
      "0.999211\n",
      "Global Step:  46700, Training Batch Accuracy:  70.6%\n",
      "1.12697\n",
      "Global Step:  46800, Training Batch Accuracy:  35.3%\n",
      "1.64162\n",
      "Global Step:  46900, Training Batch Accuracy:  70.6%\n",
      "1.22218\n",
      "Global Step:  47000, Training Batch Accuracy:  41.2%\n",
      "1.25486\n",
      "Saved checkpoint.\n",
      "Global Step:  47100, Training Batch Accuracy:  35.3%\n",
      "1.51723\n",
      "Global Step:  47200, Training Batch Accuracy:  41.2%\n",
      "1.34667\n",
      "Global Step:  47300, Training Batch Accuracy:  35.3%\n",
      "1.46795\n",
      "Global Step:  47400, Training Batch Accuracy:  41.2%\n",
      "1.4503\n",
      "Global Step:  47500, Training Batch Accuracy:  64.7%\n",
      "1.25815\n",
      "Global Step:  47600, Training Batch Accuracy:  47.1%\n",
      "1.47705\n",
      "Global Step:  47700, Training Batch Accuracy:  76.5%\n",
      "0.913942\n",
      "Global Step:  47800, Training Batch Accuracy:  58.8%\n",
      "1.13209\n",
      "Global Step:  47900, Training Batch Accuracy:  70.6%\n",
      "0.998464\n",
      "Global Step:  48000, Training Batch Accuracy:  41.2%\n",
      "1.57137\n",
      "Saved checkpoint.\n",
      "Global Step:  48100, Training Batch Accuracy:  35.3%\n",
      "1.67901\n",
      "Global Step:  48200, Training Batch Accuracy:  23.5%\n",
      "2.12377\n",
      "Global Step:  48300, Training Batch Accuracy:  52.9%\n",
      "1.27351\n",
      "Global Step:  48400, Training Batch Accuracy:  70.6%\n",
      "1.37309\n",
      "Global Step:  48500, Training Batch Accuracy:  58.8%\n",
      "0.957025\n",
      "Global Step:  48600, Training Batch Accuracy:  52.9%\n",
      "1.34975\n",
      "Global Step:  48700, Training Batch Accuracy:  47.1%\n",
      "1.47225\n",
      "Global Step:  48800, Training Batch Accuracy:  58.8%\n",
      "1.10983\n",
      "Global Step:  48900, Training Batch Accuracy:  52.9%\n",
      "1.30107\n",
      "Global Step:  49000, Training Batch Accuracy:  58.8%\n",
      "1.24571\n",
      "Saved checkpoint.\n",
      "Global Step:  49100, Training Batch Accuracy:  64.7%\n",
      "1.29503\n",
      "Global Step:  49200, Training Batch Accuracy:  52.9%\n",
      "1.21678\n",
      "Global Step:  49300, Training Batch Accuracy:  64.7%\n",
      "1.24296\n",
      "Global Step:  49400, Training Batch Accuracy:  35.3%\n",
      "1.59387\n",
      "Global Step:  49500, Training Batch Accuracy:  41.2%\n",
      "1.46224\n",
      "Global Step:  49600, Training Batch Accuracy:  41.2%\n",
      "1.48331\n",
      "Global Step:  49700, Training Batch Accuracy:  52.9%\n",
      "1.28614\n",
      "Global Step:  49800, Training Batch Accuracy:  41.2%\n",
      "1.45084\n",
      "Global Step:  49900, Training Batch Accuracy:  47.1%\n",
      "1.55006\n",
      "Global Step:  50000, Training Batch Accuracy:  41.2%\n",
      "1.28815\n",
      "Saved checkpoint.\n",
      "Global Step:  50100, Training Batch Accuracy:  47.1%\n",
      "1.5669\n",
      "Global Step:  50200, Training Batch Accuracy:  52.9%\n",
      "1.54653\n",
      "Global Step:  50300, Training Batch Accuracy:  64.7%\n",
      "1.02052\n",
      "Global Step:  50400, Training Batch Accuracy:  52.9%\n",
      "1.35436\n",
      "Global Step:  50500, Training Batch Accuracy:  35.3%\n",
      "1.54874\n",
      "Global Step:  50600, Training Batch Accuracy:  47.1%\n",
      "1.35163\n",
      "Global Step:  50700, Training Batch Accuracy:  58.8%\n",
      "1.16211\n",
      "Global Step:  50800, Training Batch Accuracy:  47.1%\n",
      "1.42951\n",
      "Global Step:  50900, Training Batch Accuracy:  35.3%\n",
      "1.65857\n",
      "Global Step:  51000, Training Batch Accuracy:  64.7%\n",
      "1.02169\n",
      "Saved checkpoint.\n",
      "Global Step:  51100, Training Batch Accuracy:  47.1%\n",
      "1.41715\n",
      "Global Step:  51200, Training Batch Accuracy:  58.8%\n",
      "1.14573\n",
      "Global Step:  51300, Training Batch Accuracy:  58.8%\n",
      "1.21251\n",
      "Global Step:  51400, Training Batch Accuracy:  70.6%\n",
      "1.07517\n",
      "Global Step:  51500, Training Batch Accuracy:  29.4%\n",
      "1.36498\n",
      "Global Step:  51600, Training Batch Accuracy:  47.1%\n",
      "1.56177\n",
      "Global Step:  51700, Training Batch Accuracy:  41.2%\n",
      "1.2549\n",
      "Global Step:  51800, Training Batch Accuracy:  41.2%\n",
      "1.23699\n",
      "Global Step:  51900, Training Batch Accuracy:  41.2%\n",
      "1.46472\n",
      "Global Step:  52000, Training Batch Accuracy:  64.7%\n",
      "1.3471\n",
      "Saved checkpoint.\n",
      "Global Step:  52100, Training Batch Accuracy:  41.2%\n",
      "1.45877\n",
      "Global Step:  52200, Training Batch Accuracy:  41.2%\n",
      "1.62217\n",
      "Global Step:  52300, Training Batch Accuracy:  47.1%\n",
      "1.26043\n",
      "Global Step:  52400, Training Batch Accuracy:  52.9%\n",
      "1.30836\n",
      "Global Step:  52500, Training Batch Accuracy:  47.1%\n",
      "1.33565\n",
      "Global Step:  52600, Training Batch Accuracy:  64.7%\n",
      "1.14633\n",
      "Global Step:  52700, Training Batch Accuracy:  47.1%\n",
      "1.70944\n",
      "Global Step:  52800, Training Batch Accuracy:  58.8%\n",
      "0.918931\n",
      "Global Step:  52900, Training Batch Accuracy:  47.1%\n",
      "1.30283\n",
      "Global Step:  53000, Training Batch Accuracy:  41.2%\n",
      "2.05608\n",
      "Saved checkpoint.\n",
      "Global Step:  53100, Training Batch Accuracy:  41.2%\n",
      "1.14164\n",
      "Global Step:  53200, Training Batch Accuracy:  64.7%\n",
      "0.838429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:  53300, Training Batch Accuracy:  29.4%\n",
      "1.89114\n",
      "Global Step:  53400, Training Batch Accuracy:  58.8%\n",
      "1.03718\n",
      "Global Step:  53500, Training Batch Accuracy:  35.3%\n",
      "1.50655\n",
      "Global Step:  53600, Training Batch Accuracy:  52.9%\n",
      "1.54544\n",
      "Global Step:  53700, Training Batch Accuracy:  35.3%\n",
      "1.59096\n",
      "Global Step:  53800, Training Batch Accuracy:  52.9%\n",
      "1.13617\n",
      "Global Step:  53900, Training Batch Accuracy:  47.1%\n",
      "1.7302\n",
      "Global Step:  54000, Training Batch Accuracy:  58.8%\n",
      "1.19483\n",
      "Saved checkpoint.\n",
      "Global Step:  54100, Training Batch Accuracy:  52.9%\n",
      "1.02363\n",
      "Global Step:  54200, Training Batch Accuracy:  35.3%\n",
      "1.36382\n",
      "Global Step:  54300, Training Batch Accuracy:  64.7%\n",
      "0.894267\n",
      "Global Step:  54400, Training Batch Accuracy:  52.9%\n",
      "1.60947\n",
      "Global Step:  54500, Training Batch Accuracy:  47.1%\n",
      "1.82183\n",
      "Global Step:  54600, Training Batch Accuracy:  76.5%\n",
      "0.897889\n",
      "Global Step:  54700, Training Batch Accuracy:  70.6%\n",
      "1.01201\n",
      "Global Step:  54800, Training Batch Accuracy:  41.2%\n",
      "1.62417\n",
      "Global Step:  54900, Training Batch Accuracy:  52.9%\n",
      "1.33564\n",
      "Global Step:  55000, Training Batch Accuracy:  58.8%\n",
      "1.17404\n",
      "Saved checkpoint.\n",
      "Global Step:  55100, Training Batch Accuracy:  64.7%\n",
      "0.944309\n",
      "Global Step:  55200, Training Batch Accuracy:  35.3%\n",
      "1.91532\n",
      "Global Step:  55300, Training Batch Accuracy:  35.3%\n",
      "1.92244\n",
      "Global Step:  55400, Training Batch Accuracy:  52.9%\n",
      "1.34114\n",
      "Global Step:  55500, Training Batch Accuracy:  58.8%\n",
      "1.28832\n",
      "Global Step:  55600, Training Batch Accuracy:  29.4%\n",
      "1.44686\n",
      "Global Step:  55700, Training Batch Accuracy:  64.7%\n",
      "1.1599\n",
      "Global Step:  55800, Training Batch Accuracy:  41.2%\n",
      "1.21628\n",
      "Global Step:  55900, Training Batch Accuracy:  76.5%\n",
      "0.803055\n",
      "Global Step:  56000, Training Batch Accuracy:  58.8%\n",
      "1.17658\n",
      "Saved checkpoint.\n",
      "Global Step:  56100, Training Batch Accuracy:  47.1%\n",
      "1.20007\n",
      "Global Step:  56200, Training Batch Accuracy:  58.8%\n",
      "1.29477\n",
      "Global Step:  56300, Training Batch Accuracy:  70.6%\n",
      "0.895868\n",
      "Global Step:  56400, Training Batch Accuracy:  41.2%\n",
      "1.45156\n",
      "Global Step:  56500, Training Batch Accuracy:  52.9%\n",
      "1.32365\n",
      "Global Step:  56600, Training Batch Accuracy:  52.9%\n",
      "1.13183\n",
      "Global Step:  56700, Training Batch Accuracy:  52.9%\n",
      "1.35285\n",
      "Global Step:  56800, Training Batch Accuracy:  41.2%\n",
      "1.54685\n",
      "Global Step:  56900, Training Batch Accuracy:  58.8%\n",
      "1.17081\n",
      "Global Step:  57000, Training Batch Accuracy:  58.8%\n",
      "1.05469\n",
      "Saved checkpoint.\n",
      "Global Step:  57100, Training Batch Accuracy:  47.1%\n",
      "1.43925\n",
      "Global Step:  57200, Training Batch Accuracy:  47.1%\n",
      "1.69256\n",
      "Global Step:  57300, Training Batch Accuracy:  58.8%\n",
      "1.00024\n",
      "Global Step:  57400, Training Batch Accuracy:  41.2%\n",
      "1.75669\n",
      "Global Step:  57500, Training Batch Accuracy:  35.3%\n",
      "1.81917\n",
      "Global Step:  57600, Training Batch Accuracy:  64.7%\n",
      "1.18776\n",
      "Global Step:  57700, Training Batch Accuracy:  41.2%\n",
      "1.39039\n",
      "Global Step:  57800, Training Batch Accuracy:  52.9%\n",
      "1.46005\n",
      "Global Step:  57900, Training Batch Accuracy:  35.3%\n",
      "1.28665\n",
      "Global Step:  58000, Training Batch Accuracy:  52.9%\n",
      "1.20036\n",
      "Saved checkpoint.\n",
      "Global Step:  58100, Training Batch Accuracy:  47.1%\n",
      "1.3115\n",
      "Global Step:  58200, Training Batch Accuracy:  88.2%\n",
      "0.623886\n",
      "Global Step:  58300, Training Batch Accuracy:  52.9%\n",
      "1.44158\n",
      "Global Step:  58400, Training Batch Accuracy:  41.2%\n",
      "1.3847\n",
      "Global Step:  58500, Training Batch Accuracy:  47.1%\n",
      "1.30615\n",
      "Global Step:  58600, Training Batch Accuracy:  52.9%\n",
      "1.3531\n",
      "Global Step:  58700, Training Batch Accuracy:  52.9%\n",
      "1.2668\n",
      "Global Step:  58800, Training Batch Accuracy:  70.6%\n",
      "0.993465\n",
      "Global Step:  58900, Training Batch Accuracy:  41.2%\n",
      "1.25684\n",
      "Global Step:  59000, Training Batch Accuracy:  47.1%\n",
      "1.20581\n",
      "Saved checkpoint.\n",
      "Global Step:  59100, Training Batch Accuracy:  52.9%\n",
      "1.11391\n",
      "Global Step:  59200, Training Batch Accuracy:  64.7%\n",
      "1.04109\n",
      "Global Step:  59300, Training Batch Accuracy:  47.1%\n",
      "1.76291\n",
      "Global Step:  59400, Training Batch Accuracy:  41.2%\n",
      "1.72466\n",
      "Global Step:  59500, Training Batch Accuracy:  29.4%\n",
      "1.88172\n",
      "Global Step:  59600, Training Batch Accuracy:  47.1%\n",
      "1.28009\n",
      "Global Step:  59700, Training Batch Accuracy:  47.1%\n",
      "1.26028\n",
      "Global Step:  59800, Training Batch Accuracy:  47.1%\n",
      "1.33794\n",
      "Global Step:  59900, Training Batch Accuracy:  47.1%\n",
      "1.40945\n",
      "Global Step:  60000, Training Batch Accuracy:  52.9%\n",
      "1.66\n",
      "Saved checkpoint.\n",
      "Global Step:  60100, Training Batch Accuracy:  41.2%\n",
      "1.41967\n",
      "Global Step:  60200, Training Batch Accuracy:  76.5%\n",
      "1.05018\n",
      "Global Step:  60300, Training Batch Accuracy:  29.4%\n",
      "1.53369\n",
      "Global Step:  60400, Training Batch Accuracy:  35.3%\n",
      "1.35431\n",
      "Global Step:  60500, Training Batch Accuracy:  41.2%\n",
      "1.30754\n",
      "Global Step:  60600, Training Batch Accuracy:  35.3%\n",
      "1.66594\n",
      "Global Step:  60700, Training Batch Accuracy:  35.3%\n",
      "1.30224\n",
      "Global Step:  60800, Training Batch Accuracy:  52.9%\n",
      "1.3232\n",
      "Global Step:  60900, Training Batch Accuracy:  70.6%\n",
      "0.848484\n",
      "Global Step:  61000, Training Batch Accuracy:  41.2%\n",
      "1.54648\n",
      "Saved checkpoint.\n",
      "Global Step:  61100, Training Batch Accuracy:  70.6%\n",
      "1.15455\n",
      "Global Step:  61200, Training Batch Accuracy:  64.7%\n",
      "1.21592\n",
      "Global Step:  61300, Training Batch Accuracy:  52.9%\n",
      "1.35096\n",
      "Global Step:  61400, Training Batch Accuracy:  47.1%\n",
      "1.35838\n",
      "Global Step:  61500, Training Batch Accuracy:  58.8%\n",
      "1.14867\n",
      "Global Step:  61600, Training Batch Accuracy:  58.8%\n",
      "1.19932\n",
      "Global Step:  61700, Training Batch Accuracy:  70.6%\n",
      "1.20235\n",
      "Global Step:  61800, Training Batch Accuracy:  58.8%\n",
      "1.2729\n",
      "Global Step:  61900, Training Batch Accuracy:  64.7%\n",
      "1.04149\n",
      "Global Step:  62000, Training Batch Accuracy:  58.8%\n",
      "1.49711\n",
      "Saved checkpoint.\n",
      "Global Step:  62100, Training Batch Accuracy:  58.8%\n",
      "1.08621\n",
      "Global Step:  62200, Training Batch Accuracy:  29.4%\n",
      "1.83519\n",
      "Global Step:  62300, Training Batch Accuracy:  58.8%\n",
      "1.37129\n",
      "Global Step:  62400, Training Batch Accuracy:  52.9%\n",
      "1.0616\n",
      "Global Step:  62500, Training Batch Accuracy:  41.2%\n",
      "1.5631\n",
      "Global Step:  62600, Training Batch Accuracy:  64.7%\n",
      "0.939282\n",
      "Global Step:  62700, Training Batch Accuracy:  47.1%\n",
      "1.66905\n",
      "Global Step:  62800, Training Batch Accuracy:  41.2%\n",
      "1.57681\n",
      "Global Step:  62900, Training Batch Accuracy:  47.1%\n",
      "1.26476\n",
      "Global Step:  63000, Training Batch Accuracy:  47.1%\n",
      "1.46691\n",
      "Saved checkpoint.\n",
      "Global Step:  63100, Training Batch Accuracy:  35.3%\n",
      "1.6863\n",
      "Global Step:  63200, Training Batch Accuracy:  70.6%\n",
      "1.02569\n",
      "Global Step:  63300, Training Batch Accuracy:  58.8%\n",
      "1.18714\n",
      "Global Step:  63400, Training Batch Accuracy:  29.4%\n",
      "1.49818\n",
      "Global Step:  63500, Training Batch Accuracy:  47.1%\n",
      "1.22072\n",
      "Global Step:  63600, Training Batch Accuracy:  41.2%\n",
      "1.53861\n",
      "Global Step:  63700, Training Batch Accuracy:  52.9%\n",
      "1.61209\n",
      "Global Step:  63800, Training Batch Accuracy:  47.1%\n",
      "1.3444\n",
      "Global Step:  63900, Training Batch Accuracy:  47.1%\n",
      "1.47844\n",
      "Global Step:  64000, Training Batch Accuracy:  70.6%\n",
      "0.939552\n",
      "Saved checkpoint.\n",
      "Global Step:  64100, Training Batch Accuracy:  35.3%\n",
      "1.36737\n",
      "Global Step:  64200, Training Batch Accuracy:  58.8%\n",
      "1.1669\n",
      "Global Step:  64300, Training Batch Accuracy:  52.9%\n",
      "1.39969\n",
      "Global Step:  64400, Training Batch Accuracy:  29.4%\n",
      "1.74356\n",
      "Global Step:  64500, Training Batch Accuracy:  58.8%\n",
      "1.3574\n",
      "Global Step:  64600, Training Batch Accuracy:  58.8%\n",
      "0.965379\n",
      "Global Step:  64700, Training Batch Accuracy:  58.8%\n",
      "1.36925\n",
      "Global Step:  64800, Training Batch Accuracy:  58.8%\n",
      "1.11061\n",
      "Global Step:  64900, Training Batch Accuracy:  64.7%\n",
      "1.04528\n",
      "Global Step:  65000, Training Batch Accuracy:  35.3%\n",
      "1.39481\n",
      "Saved checkpoint.\n",
      "Global Step:  65100, Training Batch Accuracy:  52.9%\n",
      "1.08188\n",
      "Global Step:  65200, Training Batch Accuracy:  41.2%\n",
      "1.4814\n",
      "Global Step:  65300, Training Batch Accuracy:  58.8%\n",
      "0.958341\n",
      "Global Step:  65400, Training Batch Accuracy:  47.1%\n",
      "1.12388\n",
      "Global Step:  65500, Training Batch Accuracy:  52.9%\n",
      "1.2859\n",
      "Global Step:  65600, Training Batch Accuracy:  52.9%\n",
      "1.14391\n",
      "Global Step:  65700, Training Batch Accuracy:  58.8%\n",
      "1.25191\n",
      "Global Step:  65800, Training Batch Accuracy:  70.6%\n",
      "0.891721\n",
      "Global Step:  65900, Training Batch Accuracy:  58.8%\n",
      "0.915003\n",
      "Global Step:  66000, Training Batch Accuracy:  70.6%\n",
      "1.01618\n",
      "Saved checkpoint.\n",
      "Global Step:  66100, Training Batch Accuracy:  41.2%\n",
      "1.40946\n",
      "Global Step:  66200, Training Batch Accuracy:  58.8%\n",
      "1.20717\n",
      "Global Step:  66300, Training Batch Accuracy:  23.5%\n",
      "1.89266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:  66400, Training Batch Accuracy:  64.7%\n",
      "0.873202\n",
      "Global Step:  66500, Training Batch Accuracy:  70.6%\n",
      "1.01031\n",
      "Global Step:  66600, Training Batch Accuracy:  52.9%\n",
      "1.33534\n",
      "Global Step:  66700, Training Batch Accuracy:  64.7%\n",
      "0.757848\n",
      "Global Step:  66800, Training Batch Accuracy:  70.6%\n",
      "1.03723\n",
      "Global Step:  66900, Training Batch Accuracy:  47.1%\n",
      "1.26609\n",
      "Global Step:  67000, Training Batch Accuracy:  70.6%\n",
      "1.06632\n",
      "Saved checkpoint.\n",
      "Global Step:  67100, Training Batch Accuracy:  58.8%\n",
      "1.06549\n",
      "Global Step:  67200, Training Batch Accuracy:  58.8%\n",
      "0.978537\n",
      "Global Step:  67300, Training Batch Accuracy:  58.8%\n",
      "1.04195\n",
      "Global Step:  67400, Training Batch Accuracy:  47.1%\n",
      "1.5468\n",
      "Global Step:  67500, Training Batch Accuracy:  52.9%\n",
      "1.06066\n",
      "Global Step:  67600, Training Batch Accuracy:  58.8%\n",
      "1.20989\n",
      "Global Step:  67700, Training Batch Accuracy:  35.3%\n",
      "1.31315\n",
      "Global Step:  67800, Training Batch Accuracy:  76.5%\n",
      "0.958314\n",
      "Global Step:  67900, Training Batch Accuracy:  41.2%\n",
      "1.40023\n",
      "Global Step:  68000, Training Batch Accuracy:  47.1%\n",
      "1.25056\n",
      "Saved checkpoint.\n",
      "Global Step:  68100, Training Batch Accuracy:  52.9%\n",
      "1.31386\n",
      "Global Step:  68200, Training Batch Accuracy:  47.1%\n",
      "1.21719\n",
      "Global Step:  68300, Training Batch Accuracy:  47.1%\n",
      "1.48059\n",
      "Global Step:  68400, Training Batch Accuracy:  70.6%\n",
      "0.932111\n",
      "Global Step:  68500, Training Batch Accuracy:  47.1%\n",
      "1.41105\n",
      "Global Step:  68600, Training Batch Accuracy:  52.9%\n",
      "1.12383\n",
      "Global Step:  68700, Training Batch Accuracy:  76.5%\n",
      "0.891341\n",
      "Global Step:  68800, Training Batch Accuracy:  47.1%\n",
      "1.37128\n",
      "Global Step:  68900, Training Batch Accuracy:  47.1%\n",
      "1.23773\n",
      "Global Step:  69000, Training Batch Accuracy:  47.1%\n",
      "1.82047\n",
      "Saved checkpoint.\n",
      "Global Step:  69100, Training Batch Accuracy:  41.2%\n",
      "1.51455\n",
      "Global Step:  69200, Training Batch Accuracy:  35.3%\n",
      "1.75921\n",
      "Global Step:  69300, Training Batch Accuracy:  29.4%\n",
      "1.61559\n",
      "Global Step:  69400, Training Batch Accuracy:  58.8%\n",
      "1.23555\n",
      "Global Step:  69500, Training Batch Accuracy:  58.8%\n",
      "1.16213\n",
      "Global Step:  69600, Training Batch Accuracy:  64.7%\n",
      "1.2717\n",
      "Global Step:  69700, Training Batch Accuracy:  52.9%\n",
      "1.50154\n",
      "Global Step:  69800, Training Batch Accuracy:  47.1%\n",
      "1.45925\n",
      "Global Step:  69900, Training Batch Accuracy:  35.3%\n",
      "1.58344\n",
      "Global Step:  70000, Training Batch Accuracy:  64.7%\n",
      "1.13536\n",
      "Saved checkpoint.\n",
      "Global Step:  70100, Training Batch Accuracy:  29.4%\n",
      "1.49189\n",
      "Global Step:  70200, Training Batch Accuracy:  52.9%\n",
      "1.3192\n",
      "Global Step:  70300, Training Batch Accuracy:  35.3%\n",
      "1.75295\n",
      "Global Step:  70400, Training Batch Accuracy:  58.8%\n",
      "1.22338\n",
      "Global Step:  70500, Training Batch Accuracy:  64.7%\n",
      "1.17163\n",
      "Global Step:  70600, Training Batch Accuracy:  41.2%\n",
      "1.46704\n",
      "Global Step:  70700, Training Batch Accuracy:  64.7%\n",
      "1.16783\n",
      "Global Step:  70800, Training Batch Accuracy:  70.6%\n",
      "1.05381\n",
      "Global Step:  70900, Training Batch Accuracy:  47.1%\n",
      "1.47932\n",
      "Global Step:  71000, Training Batch Accuracy:  76.5%\n",
      "0.805518\n",
      "Saved checkpoint.\n",
      "Global Step:  71100, Training Batch Accuracy:  52.9%\n",
      "1.14599\n",
      "Global Step:  71200, Training Batch Accuracy:  41.2%\n",
      "1.44065\n",
      "Global Step:  71300, Training Batch Accuracy:  64.7%\n",
      "1.0356\n",
      "Global Step:  71400, Training Batch Accuracy:  47.1%\n",
      "1.19742\n",
      "Global Step:  71500, Training Batch Accuracy:  58.8%\n",
      "1.18903\n",
      "Global Step:  71600, Training Batch Accuracy:  52.9%\n",
      "1.35917\n",
      "Global Step:  71700, Training Batch Accuracy:  52.9%\n",
      "1.40139\n",
      "Global Step:  71800, Training Batch Accuracy:  64.7%\n",
      "1.12649\n",
      "Global Step:  71900, Training Batch Accuracy:  64.7%\n",
      "1.31007\n",
      "Global Step:  72000, Training Batch Accuracy:  64.7%\n",
      "1.0806\n",
      "Saved checkpoint.\n",
      "Global Step:  72100, Training Batch Accuracy:  52.9%\n",
      "1.26126\n",
      "Global Step:  72200, Training Batch Accuracy:  47.1%\n",
      "1.5071\n",
      "Global Step:  72300, Training Batch Accuracy:  47.1%\n",
      "1.78171\n",
      "Global Step:  72400, Training Batch Accuracy:  47.1%\n",
      "1.24325\n",
      "Global Step:  72500, Training Batch Accuracy:  82.4%\n",
      "0.786142\n",
      "Global Step:  72600, Training Batch Accuracy:  47.1%\n",
      "1.13224\n",
      "Global Step:  72700, Training Batch Accuracy:  41.2%\n",
      "1.22218\n",
      "Global Step:  72800, Training Batch Accuracy:  52.9%\n",
      "1.19315\n",
      "Global Step:  72900, Training Batch Accuracy:  47.1%\n",
      "1.5678\n",
      "Global Step:  73000, Training Batch Accuracy:  47.1%\n",
      "1.41448\n",
      "Saved checkpoint.\n",
      "Global Step:  73100, Training Batch Accuracy:  70.6%\n",
      "1.02245\n",
      "Global Step:  73200, Training Batch Accuracy:  76.5%\n",
      "0.884518\n",
      "Global Step:  73300, Training Batch Accuracy:  52.9%\n",
      "1.40394\n",
      "Global Step:  73400, Training Batch Accuracy:  64.7%\n",
      "1.09852\n",
      "Global Step:  73500, Training Batch Accuracy:  47.1%\n",
      "1.5069\n",
      "Global Step:  73600, Training Batch Accuracy:  52.9%\n",
      "1.12958\n",
      "Global Step:  73700, Training Batch Accuracy:  47.1%\n",
      "1.86724\n",
      "Global Step:  73800, Training Batch Accuracy:  70.6%\n",
      "0.999743\n",
      "Global Step:  73900, Training Batch Accuracy:  35.3%\n",
      "1.24341\n",
      "Global Step:  74000, Training Batch Accuracy:  52.9%\n",
      "1.56049\n",
      "Saved checkpoint.\n",
      "Global Step:  74100, Training Batch Accuracy:  58.8%\n",
      "0.907064\n",
      "Global Step:  74200, Training Batch Accuracy:  52.9%\n",
      "0.97874\n",
      "Global Step:  74300, Training Batch Accuracy:  70.6%\n",
      "0.710403\n",
      "Global Step:  74400, Training Batch Accuracy:  35.3%\n",
      "1.61309\n",
      "Global Step:  74500, Training Batch Accuracy:  64.7%\n",
      "1.06498\n",
      "Global Step:  74600, Training Batch Accuracy:  82.4%\n",
      "0.577572\n",
      "Global Step:  74700, Training Batch Accuracy:  64.7%\n",
      "0.973154\n",
      "Global Step:  74800, Training Batch Accuracy:  35.3%\n",
      "1.67028\n",
      "Global Step:  74900, Training Batch Accuracy:  47.1%\n",
      "1.40516\n",
      "Global Step:  75000, Training Batch Accuracy:  58.8%\n",
      "0.964681\n",
      "Saved checkpoint.\n",
      "Global Step:  75100, Training Batch Accuracy:  52.9%\n",
      "1.00918\n",
      "Global Step:  75200, Training Batch Accuracy:  47.1%\n",
      "1.36214\n",
      "Global Step:  75300, Training Batch Accuracy:  64.7%\n",
      "1.17997\n",
      "Global Step:  75400, Training Batch Accuracy:  35.3%\n",
      "1.58724\n",
      "Global Step:  75500, Training Batch Accuracy:  58.8%\n",
      "1.35074\n",
      "Global Step:  75600, Training Batch Accuracy:  52.9%\n",
      "1.50591\n",
      "Global Step:  75700, Training Batch Accuracy:  35.3%\n",
      "1.51107\n",
      "Global Step:  75800, Training Batch Accuracy:  58.8%\n",
      "1.49881\n",
      "Global Step:  75900, Training Batch Accuracy:  76.5%\n",
      "0.826169\n",
      "Global Step:  76000, Training Batch Accuracy:  58.8%\n",
      "1.34509\n",
      "Saved checkpoint.\n",
      "Global Step:  76100, Training Batch Accuracy:  70.6%\n",
      "1.1466\n",
      "Global Step:  76200, Training Batch Accuracy:  41.2%\n",
      "1.12619\n",
      "Global Step:  76300, Training Batch Accuracy:  58.8%\n",
      "1.07982\n",
      "Global Step:  76400, Training Batch Accuracy:  64.7%\n",
      "0.742408\n",
      "Global Step:  76500, Training Batch Accuracy:  29.4%\n",
      "2.16635\n",
      "Global Step:  76600, Training Batch Accuracy:  47.1%\n",
      "1.14244\n",
      "Global Step:  76700, Training Batch Accuracy:  52.9%\n",
      "1.50104\n",
      "Global Step:  76800, Training Batch Accuracy:  58.8%\n",
      "1.32972\n",
      "Global Step:  76900, Training Batch Accuracy:  64.7%\n",
      "0.902483\n",
      "Global Step:  77000, Training Batch Accuracy:  47.1%\n",
      "1.16964\n",
      "Saved checkpoint.\n",
      "Global Step:  77100, Training Batch Accuracy:  35.3%\n",
      "1.51267\n",
      "Global Step:  77200, Training Batch Accuracy:  58.8%\n",
      "1.1984\n",
      "Global Step:  77300, Training Batch Accuracy:  70.6%\n",
      "1.07668\n",
      "Global Step:  77400, Training Batch Accuracy:  52.9%\n",
      "1.89901\n",
      "Global Step:  77500, Training Batch Accuracy:  58.8%\n",
      "1.3297\n",
      "Global Step:  77600, Training Batch Accuracy:  64.7%\n",
      "0.913654\n",
      "Global Step:  77700, Training Batch Accuracy:  76.5%\n",
      "0.676872\n",
      "Global Step:  77800, Training Batch Accuracy:  47.1%\n",
      "1.24713\n",
      "Global Step:  77900, Training Batch Accuracy:  47.1%\n",
      "1.38294\n",
      "Global Step:  78000, Training Batch Accuracy:  58.8%\n",
      "1.15462\n",
      "Saved checkpoint.\n",
      "Global Step:  78100, Training Batch Accuracy:  41.2%\n",
      "1.87026\n",
      "Global Step:  78200, Training Batch Accuracy:  35.3%\n",
      "1.82335\n",
      "Global Step:  78300, Training Batch Accuracy:  64.7%\n",
      "1.09244\n",
      "Global Step:  78400, Training Batch Accuracy:  47.1%\n",
      "1.33828\n",
      "Global Step:  78500, Training Batch Accuracy:  47.1%\n",
      "1.44833\n",
      "Global Step:  78600, Training Batch Accuracy:  70.6%\n",
      "1.0007\n",
      "Global Step:  78700, Training Batch Accuracy:  70.6%\n",
      "0.806586\n",
      "Global Step:  78800, Training Batch Accuracy:  58.8%\n",
      "0.974286\n",
      "Global Step:  78900, Training Batch Accuracy:  64.7%\n",
      "0.918861\n",
      "Global Step:  79000, Training Batch Accuracy:  76.5%\n",
      "0.829289\n",
      "Saved checkpoint.\n",
      "Global Step:  79100, Training Batch Accuracy:  52.9%\n",
      "1.19211\n",
      "Global Step:  79200, Training Batch Accuracy:  35.3%\n",
      "1.54916\n",
      "Global Step:  79300, Training Batch Accuracy:  41.2%\n",
      "1.66192\n",
      "Global Step:  79400, Training Batch Accuracy:  52.9%\n",
      "1.19678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:  79500, Training Batch Accuracy:  58.8%\n",
      "1.30513\n",
      "Global Step:  79600, Training Batch Accuracy:  52.9%\n",
      "1.08264\n",
      "Global Step:  79700, Training Batch Accuracy:  41.2%\n",
      "1.29745\n",
      "Global Step:  79800, Training Batch Accuracy:  58.8%\n",
      "1.08908\n",
      "Global Step:  79900, Training Batch Accuracy:  58.8%\n",
      "1.24632\n",
      "Global Step:  80000, Training Batch Accuracy:  58.8%\n",
      "1.17213\n",
      "Saved checkpoint.\n",
      "Global Step:  80100, Training Batch Accuracy:  70.6%\n",
      "0.672836\n",
      "Global Step:  80200, Training Batch Accuracy:  35.3%\n",
      "1.31784\n",
      "Global Step:  80300, Training Batch Accuracy:  64.7%\n",
      "1.10749\n",
      "Global Step:  80400, Training Batch Accuracy:  64.7%\n",
      "1.32023\n",
      "Global Step:  80500, Training Batch Accuracy:  47.1%\n",
      "1.29003\n",
      "Global Step:  80600, Training Batch Accuracy:  35.3%\n",
      "1.17551\n",
      "Global Step:  80700, Training Batch Accuracy:  58.8%\n",
      "0.829566\n",
      "Global Step:  80800, Training Batch Accuracy:  58.8%\n",
      "1.23999\n",
      "Global Step:  80900, Training Batch Accuracy:  58.8%\n",
      "1.15458\n",
      "Global Step:  81000, Training Batch Accuracy:  41.2%\n",
      "1.53111\n",
      "Saved checkpoint.\n",
      "Global Step:  81100, Training Batch Accuracy:  64.7%\n",
      "1.28753\n",
      "Global Step:  81200, Training Batch Accuracy:  47.1%\n",
      "1.20742\n",
      "Global Step:  81300, Training Batch Accuracy:  47.1%\n",
      "1.10019\n",
      "Global Step:  81400, Training Batch Accuracy:  47.1%\n",
      "1.16683\n",
      "Global Step:  81500, Training Batch Accuracy:  41.2%\n",
      "1.55319\n",
      "Global Step:  81600, Training Batch Accuracy:  70.6%\n",
      "0.959253\n",
      "Global Step:  81700, Training Batch Accuracy:  52.9%\n",
      "1.06809\n",
      "Global Step:  81800, Training Batch Accuracy:  64.7%\n",
      "1.13282\n",
      "Global Step:  81900, Training Batch Accuracy:  70.6%\n",
      "0.874078\n",
      "Global Step:  82000, Training Batch Accuracy:  64.7%\n",
      "0.971209\n",
      "Saved checkpoint.\n",
      "Global Step:  82100, Training Batch Accuracy:  41.2%\n",
      "1.19945\n",
      "Global Step:  82200, Training Batch Accuracy:  47.1%\n",
      "1.10708\n",
      "Global Step:  82300, Training Batch Accuracy:  58.8%\n",
      "0.880163\n",
      "Global Step:  82400, Training Batch Accuracy:  41.2%\n",
      "1.36823\n",
      "Global Step:  82500, Training Batch Accuracy:  70.6%\n",
      "1.20468\n",
      "Global Step:  82600, Training Batch Accuracy:  52.9%\n",
      "1.01093\n",
      "Global Step:  82700, Training Batch Accuracy:  47.1%\n",
      "1.60071\n",
      "Global Step:  82800, Training Batch Accuracy:  41.2%\n",
      "1.53352\n",
      "Global Step:  82900, Training Batch Accuracy:  52.9%\n",
      "1.5503\n",
      "Global Step:  83000, Training Batch Accuracy:  35.3%\n",
      "1.22286\n",
      "Saved checkpoint.\n",
      "Global Step:  83100, Training Batch Accuracy:  52.9%\n",
      "1.33974\n",
      "Global Step:  83200, Training Batch Accuracy:  47.1%\n",
      "1.16087\n",
      "Global Step:  83300, Training Batch Accuracy:  52.9%\n",
      "0.97055\n",
      "Global Step:  83400, Training Batch Accuracy:  58.8%\n",
      "1.0763\n",
      "Global Step:  83500, Training Batch Accuracy:  52.9%\n",
      "0.980872\n",
      "Global Step:  83600, Training Batch Accuracy:  64.7%\n",
      "0.773341\n",
      "Global Step:  83700, Training Batch Accuracy:  64.7%\n",
      "1.30121\n",
      "Global Step:  83800, Training Batch Accuracy:  64.7%\n",
      "0.93088\n",
      "Global Step:  83900, Training Batch Accuracy:  58.8%\n",
      "1.19049\n",
      "Global Step:  84000, Training Batch Accuracy:  52.9%\n",
      "1.20113\n",
      "Saved checkpoint.\n",
      "Global Step:  84100, Training Batch Accuracy:  64.7%\n",
      "0.918207\n",
      "Global Step:  84200, Training Batch Accuracy:  58.8%\n",
      "0.797319\n",
      "Global Step:  84300, Training Batch Accuracy:  64.7%\n",
      "1.28124\n",
      "Global Step:  84400, Training Batch Accuracy:  58.8%\n",
      "1.16052\n",
      "Global Step:  84500, Training Batch Accuracy:  47.1%\n",
      "1.23942\n",
      "Global Step:  84600, Training Batch Accuracy:  35.3%\n",
      "1.70532\n",
      "Global Step:  84700, Training Batch Accuracy:  58.8%\n",
      "1.03888\n",
      "Global Step:  84800, Training Batch Accuracy:  35.3%\n",
      "1.48384\n",
      "Global Step:  84900, Training Batch Accuracy:  52.9%\n",
      "1.39026\n",
      "Global Step:  85000, Training Batch Accuracy:  52.9%\n",
      "1.44401\n",
      "Saved checkpoint.\n",
      "Global Step:  85100, Training Batch Accuracy:  64.7%\n",
      "1.0553\n",
      "Global Step:  85200, Training Batch Accuracy:  64.7%\n",
      "0.870708\n",
      "Global Step:  85300, Training Batch Accuracy:  82.4%\n",
      "0.632419\n",
      "Global Step:  85400, Training Batch Accuracy:  52.9%\n",
      "1.17866\n",
      "Global Step:  85500, Training Batch Accuracy:  58.8%\n",
      "1.17102\n",
      "Global Step:  85600, Training Batch Accuracy:  47.1%\n",
      "1.35305\n",
      "Global Step:  85700, Training Batch Accuracy:  58.8%\n",
      "1.10294\n",
      "Global Step:  85800, Training Batch Accuracy:  58.8%\n",
      "1.49249\n",
      "Global Step:  85900, Training Batch Accuracy:  41.2%\n",
      "1.32608\n",
      "Global Step:  86000, Training Batch Accuracy:  52.9%\n",
      "1.15251\n",
      "Saved checkpoint.\n",
      "Global Step:  86100, Training Batch Accuracy:  58.8%\n",
      "0.926711\n",
      "Global Step:  86200, Training Batch Accuracy:  64.7%\n",
      "1.08305\n",
      "Global Step:  86300, Training Batch Accuracy:  58.8%\n",
      "0.890887\n",
      "Global Step:  86400, Training Batch Accuracy:  58.8%\n",
      "1.36637\n",
      "Global Step:  86500, Training Batch Accuracy:  47.1%\n",
      "1.13179\n",
      "Global Step:  86600, Training Batch Accuracy:  58.8%\n",
      "0.996329\n",
      "Global Step:  86700, Training Batch Accuracy:  64.7%\n",
      "1.19456\n",
      "Global Step:  86800, Training Batch Accuracy:  41.2%\n",
      "1.36682\n",
      "Global Step:  86900, Training Batch Accuracy:  58.8%\n",
      "1.1675\n",
      "Global Step:  87000, Training Batch Accuracy:  47.1%\n",
      "1.17363\n",
      "Saved checkpoint.\n",
      "Global Step:  87100, Training Batch Accuracy:  58.8%\n",
      "1.64499\n",
      "Global Step:  87200, Training Batch Accuracy:  52.9%\n",
      "1.14614\n",
      "Global Step:  87300, Training Batch Accuracy:  47.1%\n",
      "1.50656\n",
      "Global Step:  87400, Training Batch Accuracy:  70.6%\n",
      "0.882774\n",
      "Global Step:  87500, Training Batch Accuracy:  58.8%\n",
      "1.08446\n",
      "Global Step:  87600, Training Batch Accuracy:  47.1%\n",
      "1.34552\n",
      "Global Step:  87700, Training Batch Accuracy:  47.1%\n",
      "1.36843\n",
      "Global Step:  87800, Training Batch Accuracy:  58.8%\n",
      "1.06389\n",
      "Global Step:  87900, Training Batch Accuracy:  70.6%\n",
      "0.925075\n",
      "Global Step:  88000, Training Batch Accuracy:  52.9%\n",
      "1.28537\n",
      "Saved checkpoint.\n",
      "Global Step:  88100, Training Batch Accuracy:  64.7%\n",
      "0.991267\n",
      "Global Step:  88200, Training Batch Accuracy:  47.1%\n",
      "1.68713\n",
      "Global Step:  88300, Training Batch Accuracy:  47.1%\n",
      "1.64041\n",
      "Global Step:  88400, Training Batch Accuracy:  76.5%\n",
      "0.832484\n",
      "Global Step:  88500, Training Batch Accuracy:  47.1%\n",
      "1.53323\n",
      "Global Step:  88600, Training Batch Accuracy:  47.1%\n",
      "1.46171\n",
      "Global Step:  88700, Training Batch Accuracy:  64.7%\n",
      "0.979957\n",
      "Global Step:  88800, Training Batch Accuracy:  41.2%\n",
      "1.42217\n",
      "Global Step:  88900, Training Batch Accuracy:  76.5%\n",
      "0.897229\n",
      "Global Step:  89000, Training Batch Accuracy:  58.8%\n",
      "1.2437\n",
      "Saved checkpoint.\n",
      "Global Step:  89100, Training Batch Accuracy:  52.9%\n",
      "1.20052\n",
      "Global Step:  89200, Training Batch Accuracy:  52.9%\n",
      "1.13646\n",
      "Global Step:  89300, Training Batch Accuracy:  64.7%\n",
      "0.99878\n",
      "Global Step:  89400, Training Batch Accuracy:  52.9%\n",
      "1.3184\n",
      "Global Step:  89500, Training Batch Accuracy:  52.9%\n",
      "1.18499\n",
      "Global Step:  89600, Training Batch Accuracy:  47.1%\n",
      "1.09383\n",
      "Global Step:  89700, Training Batch Accuracy:  41.2%\n",
      "1.77676\n",
      "Global Step:  89800, Training Batch Accuracy:  64.7%\n",
      "1.05517\n",
      "Global Step:  89900, Training Batch Accuracy:  88.2%\n",
      "0.606182\n",
      "Global Step:  90000, Training Batch Accuracy:  64.7%\n",
      "1.23751\n",
      "Saved checkpoint.\n",
      "Global Step:  90100, Training Batch Accuracy:  58.8%\n",
      "1.29266\n",
      "Global Step:  90200, Training Batch Accuracy:  52.9%\n",
      "1.64906\n",
      "Global Step:  90300, Training Batch Accuracy:  64.7%\n",
      "1.37119\n",
      "Global Step:  90400, Training Batch Accuracy:  58.8%\n",
      "1.33562\n",
      "Global Step:  90500, Training Batch Accuracy:  64.7%\n",
      "1.02129\n",
      "Global Step:  90600, Training Batch Accuracy:  41.2%\n",
      "1.77104\n",
      "Global Step:  90700, Training Batch Accuracy:  52.9%\n",
      "0.885887\n",
      "Global Step:  90800, Training Batch Accuracy:  58.8%\n",
      "1.02986\n",
      "Global Step:  90900, Training Batch Accuracy:  29.4%\n",
      "1.82662\n",
      "Global Step:  91000, Training Batch Accuracy:  70.6%\n",
      "1.38574\n",
      "Saved checkpoint.\n",
      "Global Step:  91100, Training Batch Accuracy:  41.2%\n",
      "1.45594\n",
      "Global Step:  91200, Training Batch Accuracy:  64.7%\n",
      "1.21341\n",
      "Global Step:  91300, Training Batch Accuracy:  58.8%\n",
      "1.25709\n",
      "Global Step:  91400, Training Batch Accuracy:  52.9%\n",
      "1.116\n",
      "Global Step:  91500, Training Batch Accuracy:  52.9%\n",
      "1.39728\n",
      "Global Step:  91600, Training Batch Accuracy:  76.5%\n",
      "0.943028\n",
      "Global Step:  91700, Training Batch Accuracy:  64.7%\n",
      "0.778872\n",
      "Global Step:  91800, Training Batch Accuracy:  52.9%\n",
      "1.29836\n",
      "Global Step:  91900, Training Batch Accuracy:  70.6%\n",
      "0.760307\n",
      "Global Step:  92000, Training Batch Accuracy:  58.8%\n",
      "1.3898\n",
      "Saved checkpoint.\n",
      "Global Step:  92100, Training Batch Accuracy:  76.5%\n",
      "0.986477\n",
      "Global Step:  92200, Training Batch Accuracy:  64.7%\n",
      "1.13161\n",
      "Global Step:  92300, Training Batch Accuracy:  70.6%\n",
      "0.791532\n",
      "Global Step:  92400, Training Batch Accuracy:  76.5%\n",
      "0.974009\n",
      "Global Step:  92500, Training Batch Accuracy:  76.5%\n",
      "0.839982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:  92600, Training Batch Accuracy:  76.5%\n",
      "0.950369\n",
      "Global Step:  92700, Training Batch Accuracy:  52.9%\n",
      "0.935379\n",
      "Global Step:  92800, Training Batch Accuracy:  58.8%\n",
      "1.02466\n",
      "Global Step:  92900, Training Batch Accuracy:  52.9%\n",
      "1.45396\n",
      "Global Step:  93000, Training Batch Accuracy:  47.1%\n",
      "1.81215\n",
      "Saved checkpoint.\n",
      "Global Step:  93100, Training Batch Accuracy:  70.6%\n",
      "0.810621\n",
      "Global Step:  93200, Training Batch Accuracy:  41.2%\n",
      "1.42788\n",
      "Global Step:  93300, Training Batch Accuracy:  58.8%\n",
      "1.02743\n",
      "Global Step:  93400, Training Batch Accuracy:  70.6%\n",
      "0.809343\n",
      "Global Step:  93500, Training Batch Accuracy:  64.7%\n",
      "0.975552\n",
      "Global Step:  93600, Training Batch Accuracy:  64.7%\n",
      "0.839709\n",
      "Global Step:  93700, Training Batch Accuracy:  52.9%\n",
      "1.20857\n",
      "Global Step:  93800, Training Batch Accuracy:  58.8%\n",
      "1.1727\n",
      "Global Step:  93900, Training Batch Accuracy:  47.1%\n",
      "1.43285\n",
      "Global Step:  94000, Training Batch Accuracy:  58.8%\n",
      "1.32186\n",
      "Saved checkpoint.\n",
      "Global Step:  94100, Training Batch Accuracy:  76.5%\n",
      "0.711191\n",
      "Global Step:  94200, Training Batch Accuracy:  41.2%\n",
      "1.72531\n",
      "Global Step:  94300, Training Batch Accuracy:  70.6%\n",
      "0.788201\n",
      "Global Step:  94400, Training Batch Accuracy:  47.1%\n",
      "1.17091\n",
      "Global Step:  94500, Training Batch Accuracy:  52.9%\n",
      "1.30816\n",
      "Global Step:  94600, Training Batch Accuracy:  41.2%\n",
      "1.42045\n",
      "Global Step:  94700, Training Batch Accuracy:  64.7%\n",
      "1.21207\n",
      "Global Step:  94800, Training Batch Accuracy:  88.2%\n",
      "0.555091\n",
      "Global Step:  94900, Training Batch Accuracy:  58.8%\n",
      "1.0526\n",
      "Global Step:  95000, Training Batch Accuracy:  64.7%\n",
      "0.887451\n",
      "Saved checkpoint.\n",
      "Global Step:  95100, Training Batch Accuracy:  52.9%\n",
      "1.50908\n",
      "Global Step:  95200, Training Batch Accuracy:  76.5%\n",
      "0.91338\n",
      "Global Step:  95300, Training Batch Accuracy:  64.7%\n",
      "1.16231\n",
      "Global Step:  95400, Training Batch Accuracy:  64.7%\n",
      "1.30273\n",
      "Global Step:  95500, Training Batch Accuracy:  58.8%\n",
      "1.17646\n",
      "Global Step:  95600, Training Batch Accuracy:  52.9%\n",
      "1.2696\n",
      "Global Step:  95700, Training Batch Accuracy:  64.7%\n",
      "1.12795\n",
      "Global Step:  95800, Training Batch Accuracy:  70.6%\n",
      "0.913365\n",
      "Global Step:  95900, Training Batch Accuracy:  70.6%\n",
      "1.06213\n",
      "Global Step:  96000, Training Batch Accuracy:  58.8%\n",
      "1.112\n",
      "Saved checkpoint.\n",
      "Global Step:  96100, Training Batch Accuracy:  70.6%\n",
      "0.999947\n",
      "Global Step:  96200, Training Batch Accuracy:  70.6%\n",
      "0.91264\n",
      "Global Step:  96300, Training Batch Accuracy:  70.6%\n",
      "1.1222\n",
      "Global Step:  96400, Training Batch Accuracy:  64.7%\n",
      "1.29238\n",
      "Global Step:  96500, Training Batch Accuracy:  76.5%\n",
      "0.856597\n",
      "Global Step:  96600, Training Batch Accuracy:  35.3%\n",
      "1.75983\n",
      "Global Step:  96700, Training Batch Accuracy:  64.7%\n",
      "0.913512\n",
      "Global Step:  96800, Training Batch Accuracy:  58.8%\n",
      "0.916373\n",
      "Global Step:  96900, Training Batch Accuracy:  52.9%\n",
      "1.42744\n",
      "Global Step:  97000, Training Batch Accuracy:  64.7%\n",
      "0.946638\n",
      "Saved checkpoint.\n",
      "Global Step:  97100, Training Batch Accuracy:  47.1%\n",
      "1.33434\n",
      "Global Step:  97200, Training Batch Accuracy:  58.8%\n",
      "1.23955\n",
      "Global Step:  97300, Training Batch Accuracy:  64.7%\n",
      "1.13939\n",
      "Global Step:  97400, Training Batch Accuracy:  76.5%\n",
      "1.12512\n",
      "Global Step:  97500, Training Batch Accuracy:  35.3%\n",
      "1.60498\n",
      "Global Step:  97600, Training Batch Accuracy:  52.9%\n",
      "1.18567\n",
      "Global Step:  97700, Training Batch Accuracy:  70.6%\n",
      "0.83508\n",
      "Global Step:  97800, Training Batch Accuracy:  35.3%\n",
      "1.25593\n",
      "Global Step:  97900, Training Batch Accuracy:  58.8%\n",
      "1.40069\n",
      "Global Step:  98000, Training Batch Accuracy:  64.7%\n",
      "1.13776\n",
      "Saved checkpoint.\n",
      "Global Step:  98100, Training Batch Accuracy:  82.4%\n",
      "0.885832\n",
      "Global Step:  98200, Training Batch Accuracy:  70.6%\n",
      "0.930625\n",
      "Global Step:  98300, Training Batch Accuracy:  58.8%\n",
      "1.30742\n",
      "Global Step:  98400, Training Batch Accuracy:  58.8%\n",
      "1.32008\n",
      "Global Step:  98500, Training Batch Accuracy:  58.8%\n",
      "1.23532\n",
      "Global Step:  98600, Training Batch Accuracy:  64.7%\n",
      "0.972653\n",
      "Global Step:  98700, Training Batch Accuracy:  58.8%\n",
      "1.21262\n",
      "Global Step:  98800, Training Batch Accuracy:  58.8%\n",
      "1.3224\n",
      "Global Step:  98900, Training Batch Accuracy:  64.7%\n",
      "1.1869\n",
      "Global Step:  99000, Training Batch Accuracy:  47.1%\n",
      "1.4363\n",
      "Saved checkpoint.\n",
      "Accuracy on Test-Set: 56.3% (5633 / 10000)\n",
      "Time usage: 1:23:57\n"
     ]
    }
   ],
   "source": [
    "alexNet.train_model(images_train, labels_train, 98000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
